{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d16e42b7-7f5b-4f73-a574-26d5ab6b5177",
      "metadata": {
        "id": "d16e42b7-7f5b-4f73-a574-26d5ab6b5177"
      },
      "source": [
        "**Interactive Analysis and Predictive Modeling of Cardiometabolic Risk Using NHANES 2021–2023**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b408258-8e2e-4481-ad3d-12d147db15d4",
      "metadata": {
        "id": "3b408258-8e2e-4481-ad3d-12d147db15d4"
      },
      "source": [
        "***1.1 Introduction***\n",
        "\n",
        "\n",
        "Addressing the growing burden of cardiometabolic disease requires an understanding of the intricate interactions among eating patterns, molecular indicators, and body composition. In order to create a single, comprehensive dataset, we included laboratory results (total cholesterol), anthropometric data (BMI, waist and hip circumferences), and extensive 24-hour dietary recall metrics from NHANES. We investigated the co-occurrence of demographic characteristics, nutritional imbalances, and central adiposity using a suite of interactive Bokeh visualizations, such as stacked macronutrient bar charts, a participant-level dashboard, and scatterplots of BMI vs. age and WHR vs. BMI.\n",
        "\n",
        "Expanding upon these descriptive studies, we further created and contrasted two prediction models, a random forest classifier and a penalized logistic regression, to differentiate between participants who were normal weight and those who were overweight or obese based on important characteristics. This blend of supervised learning and exploratory visualization provides useful, personalized risk prediction as well as high-level insights into population trends. In order to guarantee that our findings may guide focused interventions without jeopardizing participant confidentially, we consistently placed a high priority on ethical data processing, stressing anonymization, permission, and privacy protections."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ad4ef09-3611-430c-b12d-330b37ded013",
      "metadata": {
        "id": "9ad4ef09-3611-430c-b12d-330b37ded013"
      },
      "source": [
        "***1.2 Now we will go through the codes and results of the analysis***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8211727-c590-40f7-a191-4aa209dd7265",
      "metadata": {
        "id": "c8211727-c590-40f7-a191-4aa209dd7265"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('future.no_silent_downcasting', True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c3979b3-0af4-4d11-b5dc-5049c9ce553e",
      "metadata": {
        "id": "8c3979b3-0af4-4d11-b5dc-5049c9ce553e"
      },
      "outputs": [],
      "source": [
        "df=pd.read_sas(r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\DEMO_L.xpt\",format=\"xport\")\n",
        "output_path=r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\Demographic.csv\"\n",
        "df.to_csv(r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\Demographic.csv\",index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eab5502f-a676-440a-a0b9-d4960a6fe67b",
      "metadata": {
        "id": "eab5502f-a676-440a-a0b9-d4960a6fe67b"
      },
      "outputs": [],
      "source": [
        "df=pd.read_sas(r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\BMX_L.xpt\",format=\"xport\")\n",
        "output_path2=r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\Body_Measure.csv\"\n",
        "df.to_csv(r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\Body_Measure.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99ac50fe-80fe-4bd8-9dad-613131857751",
      "metadata": {
        "id": "99ac50fe-80fe-4bd8-9dad-613131857751"
      },
      "outputs": [],
      "source": [
        "df=pd.read_sas(r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\DR1TOT_L.xpt\",format=\"xport\")\n",
        "output_path3=r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\Dietary1.csv\"\n",
        "df.to_csv(r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\Dietary1.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41c23740-23c4-4218-bb9c-011835e262a3",
      "metadata": {
        "id": "41c23740-23c4-4218-bb9c-011835e262a3"
      },
      "outputs": [],
      "source": [
        "df=pd.read_sas(r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\PAQ_L.xpt\",format=\"xport\")\n",
        "output_path4=r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\PhyActivity.csv\"\n",
        "df.to_csv(r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\PhyActivity.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fb283b5-a35e-48d1-857d-7e14d03899d1",
      "metadata": {
        "id": "6fb283b5-a35e-48d1-857d-7e14d03899d1"
      },
      "outputs": [],
      "source": [
        "df=pd.read_sas(r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\TCHOL_L.xpt\",format=\"xport\")\n",
        "output_path5=r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\TChol.csv\"\n",
        "df.to_csv(r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\TChol.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbe3d0ee-9166-4cfb-b8ff-adca687bfeb2",
      "metadata": {
        "id": "cbe3d0ee-9166-4cfb-b8ff-adca687bfeb2"
      },
      "outputs": [],
      "source": [
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b25b0bc6-3349-47f0-8ae0-96705b67225a",
      "metadata": {
        "id": "b25b0bc6-3349-47f0-8ae0-96705b67225a",
        "outputId": "fc98fbb9-1d99-4d8f-90c4-ec836e788c07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== SEQN Comparison ===\n",
            " Dataset  Total SEQNs  Common SEQNs  Unique SEQNs\n",
            "    demo        11933          6337          5596\n",
            "    body         8860          6337          2523\n",
            "    diet         8860          6337          2523\n",
            "activity         8153          6337          1816\n",
            "    chol         8068          6337          1731\n",
            "\n",
            "=== Order Consistency ===\n",
            " Dataset  Same Order as Demographics?\n",
            "    demo                         True\n",
            "    body                        False\n",
            "    diet                        False\n",
            "activity                        False\n",
            "    chol                        False\n"
          ]
        }
      ],
      "source": [
        "paths = {\n",
        "    'demo':   r\"C:/Users/User/OneDrive/Desktop/T1- 2025/SIT731-Data Wrangling/1.7HD/Demographic.csv\",\n",
        "    'body':  r\"C:/Users/User/OneDrive/Desktop/T1- 2025/SIT731-Data Wrangling/1.7HD/Body_Measure.csv\",\n",
        "    'diet': r\"C:/Users/User/OneDrive/Desktop/T1- 2025/SIT731-Data Wrangling/1.7HD/Dietary1.csv\",\n",
        "    'activity': r\"C:/Users/User/OneDrive/Desktop/T1- 2025/SIT731-Data Wrangling/1.7HD/PhyActivity.csv\",\n",
        "    'chol':    r\"C:/Users/User/OneDrive/Desktop/T1- 2025/SIT731-Data Wrangling/1.7HD/TChol.csv\"\n",
        "}\n",
        "\n",
        "# 2. Read SEQNs from each file into a set and list\n",
        "seqn_sets = {}\n",
        "seqn_lists = {}\n",
        "for name, path in paths.items():\n",
        "    df = pd.read_csv(path, usecols=['SEQN'])\n",
        "    seqn_sets[name] = set(df['SEQN'])\n",
        "    seqn_lists[name] = df['SEQN'].tolist()\n",
        "\n",
        "# 3. Find the intersection of all SEQNs\n",
        "common_seqns = set.intersection(*seqn_sets.values())\n",
        "\n",
        "# 4. Build a summary report\n",
        "report = []\n",
        "for name in paths:\n",
        "    total = len(seqn_lists[name])\n",
        "    common = len(common_seqns)\n",
        "    unique = total - common\n",
        "    report.append({\n",
        "        'Dataset': name,\n",
        "        'Total SEQNs': total,\n",
        "        'Common SEQNs': common,\n",
        "        'Unique SEQNs': unique\n",
        "    })\n",
        "report_df = pd.DataFrame(report)\n",
        "\n",
        "# 5. Check row‐order consistency against Demographics\n",
        "demo_order = seqn_lists['demo']\n",
        "order_report = []\n",
        "for name in paths:\n",
        "    same_order = (seqn_lists[name] == demo_order)\n",
        "    order_report.append({\n",
        "        'Dataset': name,\n",
        "        'Same Order as Demographics?': same_order\n",
        "    })\n",
        "order_df = pd.DataFrame(order_report)\n",
        "\n",
        "# 6. Print results\n",
        "print(\"=== SEQN Comparison ===\")\n",
        "print(report_df.to_string(index=False))\n",
        "print(\"\\n=== Order Consistency ===\")\n",
        "print(order_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35caa015-a2d5-4e5e-a38e-ad6ff04d56e0",
      "metadata": {
        "id": "35caa015-a2d5-4e5e-a38e-ad6ff04d56e0"
      },
      "source": [
        "So here we see that the data isn't consistent through all the 5 datasets. Hence we join them using Left Join to maintain maximum data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bec4351-07df-479e-9e97-c2dbf147b93f",
      "metadata": {
        "id": "1bec4351-07df-479e-9e97-c2dbf147b93f"
      },
      "outputs": [],
      "source": [
        "#Loading into Dataframes\n",
        "demo_df     = pd.read_csv(paths[\"demo\"])\n",
        "body_df     = pd.read_csv(paths[\"body\"])\n",
        "diet_df     = pd.read_csv(paths[\"diet\"])\n",
        "activity_df = pd.read_csv(paths[\"activity\"])\n",
        "chol_df     = pd.read_csv(paths[\"chol\"])\n",
        "\n",
        "#Standardizing SEQN dtype\n",
        "for df in (demo_df, body_df, diet_df, activity_df, chol_df):\n",
        "    df[\"SEQN\"] = df[\"SEQN\"].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb6090c8-2bda-4511-ae6a-ace4ce0d7cc5",
      "metadata": {
        "id": "cb6090c8-2bda-4511-ae6a-ace4ce0d7cc5",
        "outputId": "e7931c08-c89f-4a15-c814-3f512d1290b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows,Cols in master: (11933, 225)\n",
            "     SEQN  SDDSRVYR  RIDSTATR  RIAGENDR  RIDAGEYR  RIDAGEMN  RIDRETH1  \\\n",
            "0  130378      12.0       2.0       1.0      43.0       NaN       5.0   \n",
            "1  130379      12.0       2.0       1.0      66.0       NaN       3.0   \n",
            "2  130380      12.0       2.0       2.0      44.0       NaN       2.0   \n",
            "3  130381      12.0       2.0       2.0       5.0       NaN       5.0   \n",
            "4  130382      12.0       2.0       1.0       2.0       NaN       3.0   \n",
            "\n",
            "   RIDRETH3  RIDEXMON  RIDEXAGM  ...  PAD790Q  PAD790U  PAD800       PAD810Q  \\\n",
            "0       6.0       2.0       NaN  ...      3.0     b'W'    45.0  3.000000e+00   \n",
            "1       3.0       2.0       NaN  ...      4.0     b'W'    45.0  3.000000e+00   \n",
            "2       2.0       1.0       NaN  ...      1.0     b'W'    20.0  5.397605e-79   \n",
            "3       7.0       1.0      71.0  ...      NaN      NaN     NaN           NaN   \n",
            "4       3.0       2.0      34.0  ...      NaN      NaN     NaN           NaN   \n",
            "\n",
            "   PAD810U  PAD820  PAD680       WTPH2YR  LBXTC  LBDTCSI  \n",
            "0     b'W'    45.0   360.0  56042.129410  264.0     6.83  \n",
            "1     b'W'    45.0   480.0  37435.705647  214.0     5.53  \n",
            "2      b''     NaN   240.0  85328.844519  187.0     4.84  \n",
            "3      NaN     NaN     NaN           NaN    NaN      NaN  \n",
            "4      NaN     NaN     NaN           NaN    NaN      NaN  \n",
            "\n",
            "[5 rows x 225 columns]\n"
          ]
        }
      ],
      "source": [
        "#Iterative left join\n",
        "master = demo_df.copy()\n",
        "master = master.merge(body_df,     on=\"SEQN\", how=\"left\")\n",
        "master = master.merge(diet_df,     on=\"SEQN\", how=\"left\")\n",
        "master = master.merge(activity_df, on=\"SEQN\", how=\"left\")\n",
        "master = master.merge(chol_df,     on=\"SEQN\", how=\"left\")\n",
        "\n",
        "#Checking if join was successful\n",
        "print(\"Rows,Cols in master:\", master.shape)\n",
        "print(master.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90105437-9e75-42b2-a51f-928d8e0c52b4",
      "metadata": {
        "id": "90105437-9e75-42b2-a51f-928d8e0c52b4",
        "outputId": "71405284-0454-41aa-f398-e0797fb8962b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Master CSV written to: C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\NHANES_2021_23_master.csv\n"
          ]
        }
      ],
      "source": [
        "#Saving the merged file\n",
        "base_dir=r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\"\n",
        "out_path = os.path.join(base_dir, \"NHANES_2021_23_master.csv\")\n",
        "master.to_csv(out_path, index=False)\n",
        "print(\"Master CSV written to:\", out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e1867b-d183-4244-8ea0-7711b7d4a44a",
      "metadata": {
        "id": "f3e1867b-d183-4244-8ea0-7711b7d4a44a",
        "outputId": "16b18092-7327-43f7-a8ad-b76a83d51b50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['SEQN', 'SDDSRVYR', 'RIDSTATR', 'RIAGENDR', 'RIDAGEYR', 'RIDAGEMN', 'RIDRETH1', 'RIDRETH3', 'RIDEXMON', 'RIDEXAGM', 'DMQMILIZ', 'DMDBORN4', 'DMDYRUSR', 'DMDEDUC2', 'DMDMARTZ', 'RIDEXPRG', 'DMDHHSIZ', 'DMDHRGND', 'DMDHRAGZ', 'DMDHREDZ', 'DMDHRMAZ', 'DMDHSEDZ', 'WTINT2YR', 'WTMEC2YR', 'SDMVSTRA', 'SDMVPSU', 'INDFMPIR', 'BMDSTATS', 'BMXWT', 'BMIWT', 'BMXRECUM', 'BMIRECUM', 'BMXHEAD', 'BMIHEAD', 'BMXHT', 'BMIHT', 'BMXBMI', 'BMDBMIC', 'BMXLEG', 'BMILEG', 'BMXARML', 'BMIARML', 'BMXARMC', 'BMIARMC', 'BMXWAIST', 'BMIWAIST', 'BMXHIP', 'BMIHIP', 'WTDRD1', 'WTDR2D', 'DR1DRSTZ', 'DR1EXMER', 'DRABF', 'DRDINT', 'DR1DBIH', 'DR1DAY', 'DR1LANG', 'DR1MRESP', 'DR1HELP', 'DBQ095Z', 'DBD100', 'DRQSPREP', 'DR1STY', 'DR1SKY', 'DRQSDIET', 'DRQSDT1', 'DRQSDT2', 'DRQSDT3', 'DRQSDT4', 'DRQSDT5', 'DRQSDT6', 'DRQSDT7', 'DRQSDT8', 'DRQSDT9', 'DRQSDT10', 'DRQSDT11', 'DRQSDT12', 'DRQSDT91', 'DR1TNUMF', 'DR1TKCAL', 'DR1TPROT', 'DR1TCARB', 'DR1TSUGR', 'DR1TFIBE', 'DR1TTFAT', 'DR1TSFAT', 'DR1TMFAT', 'DR1TPFAT', 'DR1TCHOL', 'DR1TATOC', 'DR1TATOA', 'DR1TRET', 'DR1TVARA', 'DR1TACAR', 'DR1TBCAR', 'DR1TCRYP', 'DR1TLYCO', 'DR1TLZ', 'DR1TVB1', 'DR1TVB2', 'DR1TNIAC', 'DR1TVB6', 'DR1TFOLA', 'DR1TFA', 'DR1TFF', 'DR1TFDFE', 'DR1TCHL', 'DR1TVB12', 'DR1TB12A', 'DR1TVC', 'DR1TVD', 'DR1TVK', 'DR1TCALC', 'DR1TPHOS', 'DR1TMAGN', 'DR1TIRON', 'DR1TZINC', 'DR1TCOPP', 'DR1TSODI', 'DR1TPOTA', 'DR1TSELE', 'DR1TCAFF', 'DR1TTHEO', 'DR1TALCO', 'DR1TMOIS', 'DR1TS040', 'DR1TS060', 'DR1TS080', 'DR1TS100', 'DR1TS120', 'DR1TS140', 'DR1TS160', 'DR1TS180', 'DR1TM161', 'DR1TM181', 'DR1TM201', 'DR1TM221', 'DR1TP182', 'DR1TP183', 'DR1TP184', 'DR1TP204', 'DR1TP205', 'DR1TP225', 'DR1TP226', 'DR1_300', 'DR1_320Z', 'DR1_330Z', 'DR1BWATZ', 'DR1TWSZ', 'DRD340', 'DRD350A', 'DRD350AQ', 'DRD350B', 'DRD350BQ', 'DRD350C', 'DRD350CQ', 'DRD350D', 'DRD350DQ', 'DRD350E', 'DRD350EQ', 'DRD350F', 'DRD350FQ', 'DRD350G', 'DRD350GQ', 'DRD350H', 'DRD350HQ', 'DRD350I', 'DRD350IQ', 'DRD350J', 'DRD350JQ', 'DRD350K', 'DRD360', 'DRD370A', 'DRD370AQ', 'DRD370B', 'DRD370BQ', 'DRD370C', 'DRD370CQ', 'DRD370D', 'DRD370DQ', 'DRD370E', 'DRD370EQ', 'DRD370F', 'DRD370FQ', 'DRD370G', 'DRD370GQ', 'DRD370H', 'DRD370HQ', 'DRD370I', 'DRD370IQ', 'DRD370J', 'DRD370JQ', 'DRD370K', 'DRD370KQ', 'DRD370L', 'DRD370LQ', 'DRD370M', 'DRD370MQ', 'DRD370N', 'DRD370NQ', 'DRD370O', 'DRD370OQ', 'DRD370P', 'DRD370PQ', 'DRD370Q', 'DRD370QQ', 'DRD370R', 'DRD370RQ', 'DRD370S', 'DRD370SQ', 'DRD370T', 'DRD370TQ', 'DRD370U', 'DRD370UQ', 'DRD370V', 'PAD790Q', 'PAD790U', 'PAD800', 'PAD810Q', 'PAD810U', 'PAD820', 'PAD680', 'WTPH2YR', 'LBXTC', 'LBDTCSI']\n"
          ]
        }
      ],
      "source": [
        "master_path = r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\NHANES_2021_23_master.csv\"\n",
        "df = pd.read_csv(master_path)\n",
        "#Printing as a list\n",
        "print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f46587ab-7f2e-41c3-89e7-0d07d21c75c1",
      "metadata": {
        "id": "f46587ab-7f2e-41c3-89e7-0d07d21c75c1",
        "outputId": "87b94567-309c-4f70-c8ae-a7da769b740c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 columns by missingness:\n",
            "\n",
            "          missing_count  missing_pct\n",
            "BMIHEAD           11933   100.000000\n",
            "DRQSDT5           11931    99.983240\n",
            "DRD370PQ          11929    99.966480\n",
            "DRQSDT6           11926    99.941339\n",
            "DRD370JQ          11921    99.899439\n",
            "DRQSDT12          11920    99.891058\n",
            "DRD350JQ          11918    99.874298\n",
            "DRD370LQ          11915    99.849158\n",
            "BMIRECUM          11915    99.849158\n",
            "DRQSDT8           11906    99.773737\n"
          ]
        }
      ],
      "source": [
        "#Loading the merged dataset\n",
        "master_path = r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\NHANES_2021_23_master.csv\"\n",
        "df = pd.read_csv(master_path)\n",
        "\n",
        "#Computing missing values counts and percentage\n",
        "missing = df.isna().sum().to_frame('missing_count')\n",
        "missing['missing_pct'] = missing['missing_count'] / len(df) * 100\n",
        "\n",
        "#Sorting and displaying the top 10 by missing percentage\n",
        "missing = missing.sort_values('missing_pct', ascending=False)\n",
        "print(\"Top 10 columns by missingness:\\n\")\n",
        "print(missing.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "084dff6d-43ba-455f-a2b1-1906d2acb1d4",
      "metadata": {
        "id": "084dff6d-43ba-455f-a2b1-1906d2acb1d4",
        "outputId": "d5faad5f-879f-4186-cf28-705b954bd029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== DataFrame Info ===\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11933 entries, 0 to 11932\n",
            "Columns: 225 entries, SEQN to LBDTCSI\n",
            "dtypes: float64(222), int64(1), object(2)\n",
            "memory usage: 20.5+ MB\n",
            "\n",
            "=== First 5 Rows ===\n",
            "     SEQN  SDDSRVYR  RIDSTATR  RIAGENDR  RIDAGEYR  RIDAGEMN  RIDRETH1  \\\n",
            "0  130378      12.0       2.0       1.0      43.0       NaN       5.0   \n",
            "1  130379      12.0       2.0       1.0      66.0       NaN       3.0   \n",
            "2  130380      12.0       2.0       2.0      44.0       NaN       2.0   \n",
            "3  130381      12.0       2.0       2.0       5.0       NaN       5.0   \n",
            "4  130382      12.0       2.0       1.0       2.0       NaN       3.0   \n",
            "\n",
            "   RIDRETH3  RIDEXMON  RIDEXAGM  ...  PAD790Q  PAD790U  PAD800       PAD810Q  \\\n",
            "0       6.0       2.0       NaN  ...      3.0     b'W'    45.0  3.000000e+00   \n",
            "1       3.0       2.0       NaN  ...      4.0     b'W'    45.0  3.000000e+00   \n",
            "2       2.0       1.0       NaN  ...      1.0     b'W'    20.0  5.397605e-79   \n",
            "3       7.0       1.0      71.0  ...      NaN      NaN     NaN           NaN   \n",
            "4       3.0       2.0      34.0  ...      NaN      NaN     NaN           NaN   \n",
            "\n",
            "   PAD810U  PAD820  PAD680       WTPH2YR  LBXTC  LBDTCSI  \n",
            "0     b'W'    45.0   360.0  56042.129410  264.0     6.83  \n",
            "1     b'W'    45.0   480.0  37435.705647  214.0     5.53  \n",
            "2      b''     NaN   240.0  85328.844519  187.0     4.84  \n",
            "3      NaN     NaN     NaN           NaN    NaN      NaN  \n",
            "4      NaN     NaN     NaN           NaN    NaN      NaN  \n",
            "\n",
            "[5 rows x 225 columns]\n",
            "\n",
            "=== Descriptive Statistics ===\n",
            "                SEQN  SDDSRVYR      RIDSTATR      RIAGENDR      RIDAGEYR  \\\n",
            "count   11933.000000   11933.0  11933.000000  11933.000000  1.193300e+04   \n",
            "mean   136344.000000      12.0      1.742479      1.532808  3.831786e+01   \n",
            "std      3444.904716       0.0      0.437287      0.498943  2.560199e+01   \n",
            "min    130378.000000      12.0      1.000000      1.000000  5.397605e-79   \n",
            "25%    133361.000000      12.0      1.000000      1.000000  1.300000e+01   \n",
            "50%    136344.000000      12.0      2.000000      2.000000  3.700000e+01   \n",
            "75%    139327.000000      12.0      2.000000      2.000000  6.200000e+01   \n",
            "max    142310.000000      12.0      2.000000      2.000000  8.000000e+01   \n",
            "\n",
            "           RIDAGEMN      RIDRETH1      RIDRETH3     RIDEXMON      RIDEXAGM  \\\n",
            "count  3.770000e+02  11933.000000  11933.000000  8860.000000  2.787000e+03   \n",
            "mean   1.162865e+01      3.104584      3.320540     1.520203  1.219085e+02   \n",
            "std    6.805429e+00      1.076346      1.518379     0.499620  6.715865e+01   \n",
            "min    5.397605e-79      1.000000      1.000000     1.000000  5.397605e-79   \n",
            "25%    6.000000e+00      3.000000      3.000000     1.000000  6.600000e+01   \n",
            "50%    1.100000e+01      3.000000      3.000000     2.000000  1.220000e+02   \n",
            "75%    1.700000e+01      4.000000      4.000000     2.000000  1.795000e+02   \n",
            "max    2.400000e+01      5.000000      7.000000     2.000000  2.390000e+02   \n",
            "\n",
            "       ...    DRD370UQ      DRD370V       PAD790Q       PAD800       PAD810Q  \\\n",
            "count  ...  124.000000  4173.000000  8.135000e+03  6390.000000  8.139000e+03   \n",
            "mean   ...    1.790323     1.999281  6.014247e+01    93.437715  4.921084e+01   \n",
            "std    ...    1.270517     0.026806  7.417083e+02   544.415142  6.852722e+02   \n",
            "min    ...    1.000000     1.000000  5.397605e-79     1.000000  5.397605e-79   \n",
            "25%    ...    1.000000     2.000000  1.000000e+00    30.000000  5.397605e-79   \n",
            "50%    ...    1.000000     2.000000  2.000000e+00    60.000000  5.397605e-79   \n",
            "75%    ...    2.000000     2.000000  4.000000e+00    60.000000  2.000000e+00   \n",
            "max    ...    6.000000     2.000000  9.999000e+03  9999.000000  9.999000e+03   \n",
            "\n",
            "            PAD820        PAD680       WTPH2YR        LBXTC      LBDTCSI  \n",
            "count  3687.000000  8.138000e+03  8.068000e+03  6890.000000  6890.000000  \n",
            "mean     97.571467  4.469827e+02  3.774440e+04   181.541074     4.694643  \n",
            "std     605.421908  9.174642e+02  3.093795e+04    42.316140     1.094357  \n",
            "min       1.000000  5.397605e-79  5.397605e-79    62.000000     1.600000  \n",
            "25%      30.000000  1.800000e+02  1.809262e+04   151.000000     3.900000  \n",
            "50%      45.000000  3.000000e+02  3.026473e+04   178.000000     4.600000  \n",
            "75%      60.000000  4.800000e+02  4.900605e+04   207.000000     5.350000  \n",
            "max    9999.000000  9.999000e+03  2.417289e+05   438.000000    11.330000  \n",
            "\n",
            "[8 rows x 223 columns]\n"
          ]
        }
      ],
      "source": [
        "print(\"=== DataFrame Info ===\")\n",
        "df.info()\n",
        "print(\"\\n=== First 5 Rows ===\")\n",
        "print(df.head())\n",
        "print(\"\\n=== Descriptive Statistics ===\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "439412ad-eb39-4b52-ab75-0f89acb49f49",
      "metadata": {
        "id": "439412ad-eb39-4b52-ab75-0f89acb49f49"
      },
      "source": [
        "Now, we will be replacing SAS‐style sentinel values (extremely small floats <1×10⁻⁸ and large flag codes ≥9000) with NaNs, converting all string/object fields to the categorical dtype, and auto‐casting any numeric columns with fewer than 20 unique values as categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d1c144a-dcec-42d1-bc12-2e39108c7b7d",
      "metadata": {
        "id": "5d1c144a-dcec-42d1-bc12-2e39108c7b7d"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7546f9e8-5135-4803-b33d-5cc8c6fb2466",
      "metadata": {
        "id": "7546f9e8-5135-4803-b33d-5cc8c6fb2466",
        "outputId": "02a122bb-fe05-4353-caa3-bba16daaedbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11933 entries, 0 to 11932\n",
            "Columns: 225 entries, SEQN to LBDTCSI\n",
            "dtypes: category(126), float64(98), int64(1)\n",
            "memory usage: 10.5 MB\n"
          ]
        }
      ],
      "source": [
        "# Only clean numeric columns other than SEQN\n",
        "num_cols = (\n",
        "    df\n",
        "    .select_dtypes(include=['float64','int64'])\n",
        "    .columns\n",
        "    .difference(['SEQN'])\n",
        ")\n",
        "\n",
        "for c in num_cols:\n",
        "    df[c] = (\n",
        "        df[c]\n",
        "        .mask(df[c].abs() < 1e-8, np.nan)\n",
        "        .mask(df[c] >= 9000, np.nan)\n",
        "    )\n",
        "\n",
        "# Clean byte-strings in object columns\n",
        "for col in df.select_dtypes('object').columns:\n",
        "    df[col] = df[col].astype('category')\n",
        "\n",
        "# auto‐cast low‐cardinality numeric columns to category\n",
        "for col in df.select_dtypes(include=['float64','int64']).columns:\n",
        "    if df[col].nunique(dropna=False) < 20:   # tweak 20 up or down\n",
        "        df[col] = df[col].astype('category')\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fa4ba98-2bf4-4d81-9f82-973c42e6c89d",
      "metadata": {
        "id": "8fa4ba98-2bf4-4d81-9f82-973c42e6c89d"
      },
      "source": [
        "Running that will give us the complete set of variables now treated as categories—so we can scan and confirm that only the true code/flag fields (and not continuous measures like nutrient intakes) ended up in this list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "988dd36f-f403-406a-9504-6f8600899c9e",
      "metadata": {
        "id": "988dd36f-f403-406a-9504-6f8600899c9e",
        "outputId": "1863a8a1-98d8-46df-f3de-386e9271f8d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total categorical columns: 126\n",
            "SDDSRVYR\n",
            "RIDSTATR\n",
            "RIAGENDR\n",
            "RIDRETH1\n",
            "RIDRETH3\n",
            "RIDEXMON\n",
            "DMQMILIZ\n",
            "DMDBORN4\n",
            "DMDYRUSR\n",
            "DMDEDUC2\n",
            "DMDMARTZ\n",
            "RIDEXPRG\n",
            "DMDHHSIZ\n",
            "DMDHRGND\n",
            "DMDHRAGZ\n",
            "DMDHREDZ\n",
            "DMDHRMAZ\n",
            "DMDHSEDZ\n",
            "SDMVSTRA\n",
            "SDMVPSU\n",
            "BMDSTATS\n",
            "BMIWT\n",
            "BMIRECUM\n",
            "BMIHEAD\n",
            "BMIHT\n",
            "BMDBMIC\n",
            "BMILEG\n",
            "BMIARML\n",
            "BMIARMC\n",
            "BMIWAIST\n",
            "BMIHIP\n",
            "DR1DRSTZ\n",
            "DR1EXMER\n",
            "DRABF\n",
            "DRDINT\n",
            "DR1DAY\n",
            "DR1LANG\n",
            "DR1MRESP\n",
            "DR1HELP\n",
            "DBQ095Z\n",
            "DBD100\n",
            "DRQSPREP\n",
            "DR1STY\n",
            "DR1SKY\n",
            "DRQSDIET\n",
            "DRQSDT1\n",
            "DRQSDT2\n",
            "DRQSDT3\n",
            "DRQSDT4\n",
            "DRQSDT5\n",
            "DRQSDT6\n",
            "DRQSDT7\n",
            "DRQSDT8\n",
            "DRQSDT9\n",
            "DRQSDT10\n",
            "DRQSDT11\n",
            "DRQSDT12\n",
            "DRQSDT91\n",
            "DR1_300\n",
            "DR1TWSZ\n",
            "DRD340\n",
            "DRD350A\n",
            "DRD350AQ\n",
            "DRD350B\n",
            "DRD350BQ\n",
            "DRD350C\n",
            "DRD350CQ\n",
            "DRD350D\n",
            "DRD350DQ\n",
            "DRD350E\n",
            "DRD350EQ\n",
            "DRD350F\n",
            "DRD350FQ\n",
            "DRD350G\n",
            "DRD350GQ\n",
            "DRD350H\n",
            "DRD350HQ\n",
            "DRD350I\n",
            "DRD350IQ\n",
            "DRD350J\n",
            "DRD350JQ\n",
            "DRD350K\n",
            "DRD360\n",
            "DRD370A\n",
            "DRD370AQ\n",
            "DRD370B\n",
            "DRD370C\n",
            "DRD370CQ\n",
            "DRD370D\n",
            "DRD370DQ\n",
            "DRD370E\n",
            "DRD370EQ\n",
            "DRD370F\n",
            "DRD370FQ\n",
            "DRD370G\n",
            "DRD370GQ\n",
            "DRD370H\n",
            "DRD370HQ\n",
            "DRD370I\n",
            "DRD370IQ\n",
            "DRD370J\n",
            "DRD370JQ\n",
            "DRD370K\n",
            "DRD370KQ\n",
            "DRD370L\n",
            "DRD370LQ\n",
            "DRD370M\n",
            "DRD370MQ\n",
            "DRD370N\n",
            "DRD370NQ\n",
            "DRD370O\n",
            "DRD370OQ\n",
            "DRD370P\n",
            "DRD370PQ\n",
            "DRD370Q\n",
            "DRD370QQ\n",
            "DRD370R\n",
            "DRD370RQ\n",
            "DRD370S\n",
            "DRD370SQ\n",
            "DRD370T\n",
            "DRD370U\n",
            "DRD370UQ\n",
            "DRD370V\n",
            "PAD790U\n",
            "PAD810U\n"
          ]
        }
      ],
      "source": [
        "# Get all category columns\n",
        "cat_cols = df.select_dtypes(include='category').columns.tolist()\n",
        "\n",
        "\n",
        "print(f\"Total categorical columns: {len(cat_cols)}\")\n",
        "for col in cat_cols:\n",
        "    print(col)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a54fef53-561a-47f9-a123-6f824bd799f8",
      "metadata": {
        "id": "a54fef53-561a-47f9-a123-6f824bd799f8"
      },
      "source": [
        "Now we will deal with the duplicate entries in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f6146b2-3876-4d51-bc7e-b57c2f793621",
      "metadata": {
        "id": "4f6146b2-3876-4d51-bc7e-b57c2f793621",
        "outputId": "be42fbad-bca8-48bd-8d80-d1e5d1632f88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of SEQNs repeated more than once: 0\n",
            "\n",
            "Sample of duplicated SEQNs and their counts:\n",
            "Series([], Name: count, dtype: int64)\n",
            "\n",
            "Number of SEQNs repeated exactly twice: 0\n",
            "Series([], Name: count, dtype: int64)\n"
          ]
        }
      ],
      "source": [
        "# Computing frequency of each SEQN\n",
        "seqn_counts = df['SEQN'].value_counts()\n",
        "\n",
        "# Filtering to those SEQNs that appear more than once\n",
        "dup_seqns = seqn_counts[seqn_counts > 1]\n",
        "\n",
        "print(f\"Number of SEQNs repeated more than once: {dup_seqns.size}\")\n",
        "print(\"\\nSample of duplicated SEQNs and their counts:\")\n",
        "print(dup_seqns.head())\n",
        "\n",
        "dup_exactly_two = seqn_counts[seqn_counts == 2]\n",
        "print(f\"\\nNumber of SEQNs repeated exactly twice: {dup_exactly_two.size}\")\n",
        "print(dup_exactly_two.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31021eed-6b71-422a-87b9-9361f5e7f66e",
      "metadata": {
        "id": "31021eed-6b71-422a-87b9-9361f5e7f66e"
      },
      "source": [
        "Since there are no SEQNs repeated, we can skip any de-duplication step—the dataset already has exactly one row per person."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b327a72-c3dc-4ff4-b044-fd330d84f817",
      "metadata": {
        "id": "1b327a72-c3dc-4ff4-b044-fd330d84f817",
        "outputId": "45a85733-2f74-4b53-f365-dec056e6bfe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 20 most‐missing columns:\n",
            "           missing_count  missing_pct\n",
            "BMIHEAD           11933   100.000000\n",
            "DRQSDT5           11931    99.983240\n",
            "DRD370PQ          11929    99.966480\n",
            "DRQSDT6           11926    99.941339\n",
            "DRD370JQ          11921    99.899439\n",
            "DRQSDT12          11920    99.891058\n",
            "DRD350JQ          11918    99.874298\n",
            "BMIRECUM          11915    99.849158\n",
            "DRD370LQ          11915    99.849158\n",
            "WTDR2D            11908    99.790497\n",
            "DRQSDT8           11906    99.773737\n",
            "DRQSDT11          11901    99.731836\n",
            "DRQSDT10          11900    99.723456\n",
            "DRQSDT4           11889    99.631275\n",
            "DRD370QQ          11888    99.622894\n",
            "WTDRD1            11886    99.606134\n",
            "WTPH2YR           11884    99.589374\n",
            "DRD370CQ          11873    99.497193\n",
            "DRD350CQ          11871    99.480432\n",
            "BMXHEAD           11863    99.413391\n",
            "\n",
            "Bottom 20 least‐missing columns:\n",
            "           missing_count  missing_pct\n",
            "BMXBMI             3462    29.011984\n",
            "BMXHT              3434    28.777340\n",
            "BMXARMC            3371    28.249392\n",
            "BMXARML            3365    28.199112\n",
            "BMXWT              3179    26.640409\n",
            "BMDSTATS           3073    25.752116\n",
            "RIDEXMON           3073    25.752116\n",
            "DR1DRSTZ           3073    25.752116\n",
            "INDFMPIR           2141    17.941842\n",
            "RIDAGEYR            189     1.583843\n",
            "DMDBORN4             19     0.159222\n",
            "RIAGENDR              0     0.000000\n",
            "RIDSTATR              0     0.000000\n",
            "SDDSRVYR              0     0.000000\n",
            "RIDRETH1              0     0.000000\n",
            "RIDRETH3              0     0.000000\n",
            "DMDHHSIZ              0     0.000000\n",
            "SDMVSTRA              0     0.000000\n",
            "SDMVPSU               0     0.000000\n",
            "SEQN                  0     0.000000\n"
          ]
        }
      ],
      "source": [
        "miss = df.isna().sum().to_frame(name='missing_count')\n",
        "miss['missing_pct'] = miss['missing_count'] / len(df) * 100\n",
        "\n",
        "miss = miss.sort_values('missing_pct', ascending=False)\n",
        "\n",
        "print(\"Top 20 most‐missing columns:\\n\", miss.head(20))\n",
        "print(\"\\nBottom 20 least‐missing columns:\\n\", miss.tail(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57cabb0e-17de-46f6-b30d-007765ee2c41",
      "metadata": {
        "id": "57cabb0e-17de-46f6-b30d-007765ee2c41"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28fe8aaf-1d45-4fb2-8817-acb122d44a55",
      "metadata": {
        "id": "28fe8aaf-1d45-4fb2-8817-acb122d44a55",
        "outputId": "7e26844e-698b-4960-c4d6-754bb219860a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subset head:\n",
            " 0    130378\n",
            "1    130379\n",
            "2    130380\n",
            "3    130381\n",
            "4    130382\n",
            "Name: SEQN, dtype: int64\n",
            "Original shape: (11933, 225)\n",
            "Subset shape : (11933, 36)\n",
            "Columns kept   : ['SEQN', 'RIAGENDR', 'RIDAGEYR', 'RIDRETH3', 'DMDBORN4', 'DMDEDUC2', 'DMDMARTZ', 'DMDHHSIZ', 'WTINT2YR', 'WTMEC2YR', 'INDFMPIR', 'BMXWT', 'BMXHT', 'BMXBMI', 'BMXWAIST', 'BMXHIP', 'WTDRD1', 'WTDR2D', 'DR1TNUMF', 'DR1TKCAL', 'DR1TPROT', 'DR1TCARB', 'DR1TSUGR', 'DR1TFIBE', 'DR1TTFAT', 'DR1TSFAT', 'DR1TMFAT', 'DR1TPFAT', 'DR1TCHOL', 'PAD790Q', 'PAD800', 'PAD810Q', 'PAD820', 'PAD680', 'WTPH2YR', 'LBXTC']\n"
          ]
        }
      ],
      "source": [
        "#Defining the final list of columns to keep\n",
        "keep_cols = [\n",
        "    # ID\n",
        "    'SEQN',\n",
        "    # Demographics\n",
        "    'RIAGENDR', 'RIDAGEYR', 'RIDRETH3',\n",
        "    'DMDBORN4', 'DMDEDUC2', 'DMDMARTZ', 'DMDHHSIZ',\n",
        "    'WTINT2YR', 'WTMEC2YR', 'INDFMPIR',\n",
        "    # Body measures\n",
        "    'BMXWT', 'BMXHT', 'BMXBMI', 'BMXWAIST', 'BMXHIP',\n",
        "    # Dietary recall\n",
        "    'WTDRD1', 'WTDR2D', 'DR1TNUMF',\n",
        "    'DR1TKCAL', 'DR1TPROT', 'DR1TCARB', 'DR1TSUGR', 'DR1TFIBE', 'DR1TTFAT',\n",
        "    'DR1TSFAT', 'DR1TMFAT', 'DR1TPFAT', 'DR1TCHOL',\n",
        "    # Physical activity\n",
        "    'PAD790Q', 'PAD800', 'PAD810Q', 'PAD820', 'PAD680',\n",
        "    # Laboratory\n",
        "    'WTPH2YR', 'LBXTC'\n",
        "]\n",
        "\n",
        "#Subset to only the selected columns\n",
        "df_selected = df[keep_cols].copy()\n",
        "print(\"Subset head:\\n\", df_selected['SEQN'].head())\n",
        "\n",
        "print(\"Original shape:\", df.shape)\n",
        "print(\"Subset shape :\", df_selected.shape)\n",
        "print(\"Columns kept   :\", df_selected.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f44a953-a70e-4a4a-976d-0582eefd2cfa",
      "metadata": {
        "id": "0f44a953-a70e-4a4a-976d-0582eefd2cfa",
        "outputId": "a2acce5c-7d24-49bd-b69f-d48b38dd7cf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected dataset saved to: C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\NHANES_master_selected.csv\n"
          ]
        }
      ],
      "source": [
        "#Saving the pared-down dataset\n",
        "out_path = os.path.join(base_dir, \"NHANES_master_selected.csv\")\n",
        "df_selected.to_csv(out_path, index=False)\n",
        "print(\"Selected dataset saved to:\", out_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c81c7ae-c751-45c2-81b0-353ac126838f",
      "metadata": {
        "id": "6c81c7ae-c751-45c2-81b0-353ac126838f"
      },
      "source": [
        "Following our domain goals and decisions about variable importance (whether to \"keep\" or \"drop\"), we created a definitive list of 36 crucial variables. Total dietary intakes (energy, macronutrients, fiber, cholesterol), summary physical activity metrics (frequency and duration of moderate/vigorous activity plus sedentary time), core demographics (age, gender, race/ethnicity, education, and income), basic anthropometrics (weight, height, BMI, waist and hip circumferences), participant weights for survey-weighted analyses, and the primary laboratory outcome (total serum cholesterol) were among these. Every other column, including metadata flags, highly specialized sub-measures, and micronutrient breakdowns with a lot of missing data, was eliminated because it was thought to be unrelated to our main study concerns."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4bb2c46-1e9c-4d07-ba00-e6ec30667c42",
      "metadata": {
        "id": "f4bb2c46-1e9c-4d07-ba00-e6ec30667c42"
      },
      "source": [
        "Now we will deal with the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88c71177-0d1a-41ba-bc86-cf5cc4f61f3d",
      "metadata": {
        "id": "88c71177-0d1a-41ba-bc86-cf5cc4f61f3d"
      },
      "outputs": [],
      "source": [
        "#Separating numeric vs. categorical columns\n",
        "num_cols = df.select_dtypes(include=['float64','int64']).columns.tolist()\n",
        "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n",
        "\n",
        "#Imputing numeric columns with the median\n",
        "for col in cat_cols:\n",
        "    # fill missing with “Unknown”\n",
        "    filled = df[col].astype('object').fillna('Unknown')\n",
        "    # infer the best dtype and then cast to category\n",
        "    df[col] = filled.infer_objects().astype('category')\n",
        "\n",
        "#Imputing categorical columns with \"Unknown\"\n",
        "for col in cat_cols:\n",
        "    df[col] = df[col].astype('object').fillna('Unknown').astype('category')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a26ebdef-311b-46cc-b97a-9d3be883e80d",
      "metadata": {
        "id": "a26ebdef-311b-46cc-b97a-9d3be883e80d",
        "outputId": "ea72e991-670f-4da1-8894-08ef0585efc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total missing values after imputation: 605353\n"
          ]
        }
      ],
      "source": [
        "#Verifying no missing values remain\n",
        "missing_after = df.isna().sum().sum()\n",
        "print(f\"Total missing values after imputation: {missing_after}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41e28944-c64b-42fc-859e-19416cac0ea8",
      "metadata": {
        "id": "41e28944-c64b-42fc-859e-19416cac0ea8",
        "outputId": "d12be192-c7b3-448d-b070-fce8acc29946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imputed dataset saved to: C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\NHANES_master_imputed.csv\n"
          ]
        }
      ],
      "source": [
        "#Saving the imputed dataset\n",
        "out_path = os.path.join(base_dir, \"NHANES_master_imputed.csv\")\n",
        "df.to_csv(out_path, index=False)\n",
        "print(f\"Imputed dataset saved to: {out_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b362fca-745c-4b42-a86f-d3984aa450ba",
      "metadata": {
        "id": "0b362fca-745c-4b42-a86f-d3984aa450ba"
      },
      "source": [
        "Now that we’ve imputed all missing values, the next logical step is to detect and tame any extreme outliers in our continuous measures so they don’t dominate our visuals or skew analyses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6c11ac4-6818-4585-bfeb-2e30c606d76d",
      "metadata": {
        "id": "f6c11ac4-6818-4585-bfeb-2e30c606d76d"
      },
      "outputs": [],
      "source": [
        "#Load the imputed dataset\n",
        "base_dir = r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\"\n",
        "imp_path = os.path.join(base_dir, \"NHANES_master_imputed.csv\")\n",
        "df = pd.read_csv(imp_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "990e7f6f-6594-40c0-a9fb-be246ee5d45b",
      "metadata": {
        "id": "990e7f6f-6594-40c0-a9fb-be246ee5d45b"
      },
      "outputs": [],
      "source": [
        "#Identifying continuous numeric columns (excluding ID)\n",
        "num_cols = df.select_dtypes(include=['float64','int64']).columns.tolist()\n",
        "num_cols = [c for c in num_cols if c != 'SEQN']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49ed92e6-82a5-46f3-a511-f1f7b24a6581",
      "metadata": {
        "id": "49ed92e6-82a5-46f3-a511-f1f7b24a6581",
        "outputId": "8bba7a64-0a48-4dcd-ce4b-78aa19d38dc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Winsorized summary (min,1%,25%,50%,75%,99%,max):\n",
            "\n",
            "                  min           1%          25%          50%          75%  \\\n",
            "SDDSRVYR    12.000000    12.000000    12.000000    12.000000    12.000000   \n",
            "RIDSTATR     1.000000     1.000000     1.000000     2.000000     2.000000   \n",
            "RIAGENDR     1.000000     1.000000     1.000000     2.000000     2.000000   \n",
            "RIDAGEYR     1.000000     1.000000    14.000000    38.000000    62.000000   \n",
            "RIDAGEMN     1.000000     1.000000     7.000000    12.000000    18.000000   \n",
            "...               ...          ...          ...          ...          ...   \n",
            "PAD820       5.000000     5.000000    30.000000    45.000000    60.000000   \n",
            "PAD680      30.000000    30.000000   180.000000   300.000000   480.000000   \n",
            "WTPH2YR   5266.131584  5720.772538  7134.269094  7966.538487  8484.029655   \n",
            "LBXTC      101.890000   101.987900   151.000000   178.000000   207.000000   \n",
            "LBDTCSI      2.636700     2.639637     3.900000     4.600000     5.350000   \n",
            "\n",
            "                  99%          max         mean         std  \n",
            "SDDSRVYR    12.000000    12.000000    12.000000    0.000000  \n",
            "RIDSTATR     2.000000     2.000000     1.742479    0.437287  \n",
            "RIAGENDR     2.000000     2.000000     1.532808    0.498943  \n",
            "RIDAGEYR    80.000000    80.000000    38.934520   25.337717  \n",
            "RIDAGEMN    24.000000    24.000000    12.177778    6.465383  \n",
            "...               ...          ...          ...         ...  \n",
            "PAD820     300.000000   300.000000    59.361187   50.077940  \n",
            "PAD680     960.000000   960.000000   362.004837  206.529295  \n",
            "WTPH2YR   8957.679709  8960.320261  7821.475487  834.211001  \n",
            "LBXTC      300.012100   300.110000   181.342671   41.088138  \n",
            "LBDTCSI      7.760242     7.762200     4.689552    1.062605  \n",
            "\n",
            "[106 rows x 9 columns]\n"
          ]
        }
      ],
      "source": [
        "#Winsorizing each at the 1st and 99th percentiles\n",
        "for c in num_cols:\n",
        "    low, high = df[c].quantile([0.01, 0.99])\n",
        "    df[c] = df[c].clip(lower=low, upper=high)\n",
        "\n",
        "#Computing descriptive stats including the 1st and 99th percentiles\n",
        "winsor_stats = df[num_cols].describe(percentiles=[.01, .25, .5, .75, .99]).T\n",
        "\n",
        "#Selecting the key columns to inspect\n",
        "winsor_stats = winsor_stats[['min', '1%', '25%', '50%', '75%', '99%', 'max', 'mean', 'std']]\n",
        "\n",
        "#Printing the table\n",
        "print(\"Winsorized summary (min,1%,25%,50%,75%,99%,max):\\n\")\n",
        "print(winsor_stats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5db64421-a49b-4e83-8f93-f420a3964eb1",
      "metadata": {
        "id": "5db64421-a49b-4e83-8f93-f420a3964eb1"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f220f943-9cfb-4e37-ac61-117a066f7c89",
      "metadata": {
        "id": "f220f943-9cfb-4e37-ac61-117a066f7c89",
        "outputId": "3a374a9f-78f2-4540-fc19-a14015c0dd32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          original_skew  log1p_skew\n",
            "DR1TP225       5.955781    5.573126\n",
            "DR1TP205       5.945671    5.419029\n",
            "DR1TP226       5.075711    4.440625\n",
            "DR1TP184       3.738538    3.637175\n",
            "DR1TB12A       3.419295    1.619609\n",
            "...                 ...         ...\n",
            "DR1TPHOS       1.064115   -0.519477\n",
            "RIDRETH3       1.041638   -0.064933\n",
            "RIDSTATR      -1.109200   -1.109200\n",
            "BMXHT         -1.478349   -1.895137\n",
            "BMXARML       -1.488429   -2.094417\n",
            "\n",
            "[72 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# 1. Compute original skews\n",
        "orig_skews = df[num_cols].skew().sort_values(ascending=False)\n",
        "\n",
        "# 2. Pick columns with |skew| > 1 to transform\n",
        "to_log = orig_skews[orig_skews.abs() > 1].index.tolist()\n",
        "\n",
        "# 3. Create the log1p versions in a new DataFrame\n",
        "log_df = pd.DataFrame({\n",
        "    col: np.log1p(df[col])\n",
        "    for col in to_log\n",
        "})\n",
        "\n",
        "# 4. Compute skewness of each log‐column directly from log_df\n",
        "log_skews = log_df.skew().sort_values(ascending=False)\n",
        "\n",
        "# 5. Build comparison table, aligning by column name\n",
        "skew_compare = pd.DataFrame({\n",
        "    'original_skew': orig_skews[to_log],\n",
        "    'log1p_skew':    log_skews[to_log]\n",
        "})\n",
        "\n",
        "# 6. (Optionally) if you want to keep the log columns in df:\n",
        "df = pd.concat([df, log_df.add_suffix('_log')], axis=1)\n",
        "\n",
        "# 7. Show results\n",
        "print(skew_compare)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee39288d-7f97-4b18-b8df-2e4db1091e92",
      "metadata": {
        "id": "ee39288d-7f97-4b18-b8df-2e4db1091e92"
      },
      "source": [
        "After winsorizing at the 1st and 99th percentiles and applying a log₁₊ₓ transformation to our most heavily skewed variables, the vast majority of distributions now lie well within a visually interpretable range. While a small number of series still exhibit post‐log skew values exceeding ±2, this degree of asymmetry will not dominate our interactive Bokeh plots—zooming, panning, and axis scaling will allow users to explore both central tendencies and the tails without a few extreme observations compressing the bulk of the data into a narrow band. More aggressive techniques (e.g. Box–Cox transforms or tighter percentile capping) could further normalize these outliers, but at the cost of interpretability and the risk of obscuring legitimately extreme but valid responses. For our purposes—providing clear, intuitive, and data‐driven visualizations—the combination of winsorizing plus log₁₊ₓ strikes the optimal balance between outlier mitigation and preservation of real variation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dd872fe-bc2a-491c-8ce2-bf5c4d2b7073",
      "metadata": {
        "id": "3dd872fe-bc2a-491c-8ce2-bf5c4d2b7073"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "from bokeh.io import output_notebook, show, output_file, save\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.models import (ColumnDataSource, HoverTool, CategoricalColorMapper,\n",
        "                         Legend, LegendItem, NumeralTickFormatter, BoxSelectTool,\n",
        "                         RangeTool, Slider, CustomJS, RadioButtonGroup, Select,\n",
        "                         Tabs, Panel, DataTable, TableColumn, Button)\n",
        "from bokeh.layouts import column, row, gridplot\n",
        "from bokeh.palettes import Category10, Spectral6, Viridis256\n",
        "from bokeh.transform import factor_cmap, jitter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19d0ca79-8aba-4ca6-a836-8e9b80038199",
      "metadata": {
        "id": "19d0ca79-8aba-4ca6-a836-8e9b80038199"
      },
      "outputs": [],
      "source": [
        "# Read the CSV data\n",
        "data = pd.read_csv(r'C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\NHANES_master_imputed.csv')\n",
        "\n",
        "# VISUALIZATION 1: BMI Distribution by Age and Gender with Hover Info\n",
        "def create_bmi_scatter():\n",
        "    # Filter rows with valid BMI and age data\n",
        "    bmi_data = data[['RIDAGEYR', 'RIAGENDR', 'BMXBMI', 'BMXWT', 'BMXHT', 'BMXWAIST']].dropna(subset=['BMXBMI', 'RIDAGEYR'])\n",
        "\n",
        "    # Map gender codes to labels\n",
        "    bmi_data['Gender'] = bmi_data['RIAGENDR'].map({1: 'Male', 2: 'Female'})\n",
        "\n",
        "    # Create BMI category\n",
        "    def bmi_category(bmi):\n",
        "        if bmi < 18.5:\n",
        "            return 'Underweight'\n",
        "        elif bmi < 25:\n",
        "            return 'Normal'\n",
        "        elif bmi < 30:\n",
        "            return 'Overweight'\n",
        "        else:\n",
        "            return 'Obese'\n",
        "\n",
        "    bmi_data['BMI_Category'] = bmi_data['BMXBMI'].apply(bmi_category)\n",
        "\n",
        "    # Prepare data source\n",
        "    source = ColumnDataSource(data=dict(\n",
        "        age=bmi_data['RIDAGEYR'],\n",
        "        bmi=bmi_data['BMXBMI'],\n",
        "        gender=bmi_data['Gender'],\n",
        "        weight=bmi_data['BMXWT'],\n",
        "        height=bmi_data['BMXHT'],\n",
        "        waist=bmi_data['BMXWAIST'],\n",
        "        category=bmi_data['BMI_Category']\n",
        "    ))\n",
        "\n",
        "    # Create color mappers\n",
        "    gender_mapper = CategoricalColorMapper(factors=['Male', 'Female'], palette=['#1f77b4', '#ff7f0e'])\n",
        "    category_mapper = CategoricalColorMapper(\n",
        "        factors=['Underweight', 'Normal', 'Overweight', 'Obese'],\n",
        "        palette=['#2ca02c', '#1f77b4', '#ff7f0e', '#d62728']\n",
        "    )\n",
        "\n",
        "    # Create the figure\n",
        "    p = figure(\n",
        "        title='BMI Distribution by Age and Gender',\n",
        "        x_axis_label='Age (years)',\n",
        "        y_axis_label='BMI (kg/m²)',\n",
        "        width=800,\n",
        "        height=500,\n",
        "        tools='pan,box_select,zoom_in,zoom_out,reset,save'\n",
        "    )\n",
        "\n",
        "    # Add scatter points with both gender and category information\n",
        "    gender_scatter = p.circle(\n",
        "        'age', 'bmi',\n",
        "        source=source,\n",
        "        size=12,\n",
        "        alpha=0.7,\n",
        "        color={'field': 'gender', 'transform': gender_mapper},\n",
        "        line_color='black'\n",
        "    )\n",
        "\n",
        "    # Add hover tool\n",
        "    hover = HoverTool(\n",
        "        tooltips=[\n",
        "            ('Age', '@age years'),\n",
        "            ('Gender', '@gender'),\n",
        "            ('BMI', '@bmi{0.0} kg/m²'),\n",
        "            ('Category', '@category'),\n",
        "            ('Weight', '@weight{0.0} kg'),\n",
        "            ('Height', '@height{0.0} cm'),\n",
        "            ('Waist', '@waist{0.0} cm')\n",
        "        ],\n",
        "        renderers=[gender_scatter]\n",
        "    )\n",
        "    p.add_tools(hover)\n",
        "\n",
        "    # Add BMI category reference lines\n",
        "    p.line([0, 100], [18.5, 18.5], line_color='green', line_dash='dashed', line_width=2, legend_label='Underweight < 18.5')\n",
        "    p.line([0, 100], [25, 25], line_color='blue', line_dash='dashed', line_width=2, legend_label='Normal 18.5-24.9')\n",
        "    p.line([0, 100], [30, 30], line_color='orange', line_dash='dashed', line_width=2, legend_label='Overweight 25-29.9')\n",
        "\n",
        "    # Customize legend\n",
        "    p.legend.location = \"top_left\"\n",
        "    p.legend.click_policy = \"hide\"\n",
        "\n",
        "    return p"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "397076cc-df9c-4036-81f6-89667daec112",
      "metadata": {
        "id": "397076cc-df9c-4036-81f6-89667daec112"
      },
      "source": [
        "***Visualization 1: BMI Distribution by Age and Gender***\n",
        "\n",
        "Each participant's BMI is plotted against their age in this scatter plot, with dots colored according to gender (orange for females, blue for males). Standard BMI standards for underweight (< 18.5), normal (18.5–24.9), and overweight (25–29.9) are shown by dashed horizontal lines.\n",
        "\n",
        "***Key Insights***\n",
        "- Predominance of overweight and obesity: Most participants fall above the normal BMI range, with a substantial cluster in the obese category (BMI ≥ 30) and very few underweight observations.\n",
        "- Variations in distribution by gender: Female BMIs (orange) range from roughly 15 to 75 kg/m², but male BMIs (blue) are more closely clustered around 20 to 45 kg/m².\n",
        "- Extreme numbers for a range of ages: All age groups are affected by extreme obesity, as evidenced by the fact that the two highest BMIs (over 60 kg/m2) are seen in both younger and older persons.\n",
        "- Association between central adiposity: The relationship between central fat distribution and metabolic risk is shown by interactive hover, which shows that those with higher BMIs frequently have larger waist measurements.\n",
        "\n",
        "***Implications***\n",
        "- The high rate of overweight/obesity in this population suggests a higher risk of chronic diseases.\n",
        "- Females' greater BMI variability raises the possibility that gender-specific therapies are required.\n",
        "- By displaying age, gender, BMI, category, weight, height, and waist, the interactive hover functionality allows for comprehensive, individual-level assessment and focused preventative measures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e70e344-2ba4-4d40-aeb1-bd2b43d745c1",
      "metadata": {
        "id": "7e70e344-2ba4-4d40-aeb1-bd2b43d745c1"
      },
      "outputs": [],
      "source": [
        "# VISUALIZATION 2: Interactive Macronutrient Breakdown by Participant\n",
        "def create_macronutrient_chart():\n",
        "    # Filter to participants with dietary data\n",
        "    diet_data = data[['SEQN', 'RIDAGEYR', 'RIAGENDR', 'DR1TKCAL', 'DR1TPROT', 'DR1TCARB', 'DR1TTFAT']].dropna()\n",
        "\n",
        "    # Calculate macronutrient percentages\n",
        "    diet_data['Protein_pct'] = diet_data['DR1TPROT'] * 4 / diet_data['DR1TKCAL'] * 100\n",
        "    diet_data['Carbs_pct'] = diet_data['DR1TCARB'] * 4 / diet_data['DR1TKCAL'] * 100\n",
        "    diet_data['Fat_pct'] = diet_data['DR1TTFAT'] * 9 / diet_data['DR1TKCAL'] * 100\n",
        "\n",
        "    # Map gender codes to labels\n",
        "    diet_data['Gender'] = diet_data['RIAGENDR'].map({1: 'Male', 2: 'Female'})\n",
        "\n",
        "    # Create age category\n",
        "    def age_category(age):\n",
        "        if age < 18:\n",
        "            return 'Child/Teen (<18)'\n",
        "        elif age < 35:\n",
        "            return 'Young Adult (18-34)'\n",
        "        elif age < 50:\n",
        "            return 'Middle Age (35-49)'\n",
        "        elif age < 65:\n",
        "            return 'Older Adult (50-64)'\n",
        "        else:\n",
        "            return 'Senior (65+)'\n",
        "\n",
        "    diet_data['Age_Group'] = diet_data['RIDAGEYR'].apply(age_category)\n",
        "\n",
        "    # Create sorted indices by total calories\n",
        "    sorted_indices = diet_data.sort_values('DR1TKCAL').index\n",
        "\n",
        "    # Add participant ID for display using SEQN\n",
        "    diet_data['Participant'] = diet_data['SEQN'].astype(str)\n",
        "\n",
        "    # Prepare data\n",
        "    participants = diet_data['Participant'].tolist()\n",
        "    protein = diet_data['Protein_pct'].round(1).tolist()\n",
        "    carbs = diet_data['Carbs_pct'].round(1).tolist()\n",
        "    fat = diet_data['Fat_pct'].round(1).tolist()\n",
        "    calories = diet_data['DR1TKCAL'].round(0).astype(int).tolist()\n",
        "    gender = diet_data['Gender'].tolist()\n",
        "    age = diet_data['RIDAGEYR'].tolist()\n",
        "    age_group = diet_data['Age_Group'].tolist()\n",
        "\n",
        "    # Create data for stacked bars\n",
        "    protein_vals = np.array(protein)\n",
        "    carbs_vals = np.array(carbs)\n",
        "    fat_vals = np.array(fat)\n",
        "\n",
        "    # Calculate cumulative values for stacking\n",
        "    protein_right = protein_vals\n",
        "    carbs_right = protein_vals + carbs_vals\n",
        "    fat_right = protein_vals + carbs_vals + fat_vals\n",
        "\n",
        "    # Create data source\n",
        "    source = ColumnDataSource(data=dict(\n",
        "        participants=participants,\n",
        "        protein=protein_vals,\n",
        "        carbs=carbs_vals,\n",
        "        fat=fat_vals,\n",
        "        protein_right=protein_right,\n",
        "        carbs_right=carbs_right,\n",
        "        fat_right=fat_right,\n",
        "        calories=calories,\n",
        "        gender=gender,\n",
        "        age=age,\n",
        "        age_group=age_group,\n",
        "        y_range=list(range(len(participants)))\n",
        "    ))\n",
        "\n",
        "    # Create figure\n",
        "    p = figure(\n",
        "    y_range=participants,\n",
        "    title=\"Macronutrient Distribution by Participant\",\n",
        "    width=800, height=400,\n",
        "    x_range=(0, 100),\n",
        "    tools=\"pan,box_zoom,reset,save\")\n",
        "\n",
        "    # Add horizontal bars for each macronutrient\n",
        "    protein_bar = p.hbar(\n",
        "    y='y_range', right='protein_right', height=0.8,\n",
        "    source=source, color=\"#1f77b4\", legend_label=\"Protein\")\n",
        "\n",
        "    # For carbs\n",
        "    carbs_bar = p.hbar(\n",
        "    y='y_range', right='carbs_right', left='protein_right',\n",
        "    height=0.8, source=source, color=\"#ff7f0e\",\n",
        "    legend_label=\"Carbohydrates\")\n",
        "\n",
        "    # For fat\n",
        "    fat_bar = p.hbar(\n",
        "    y='y_range', right='fat_right', left='carbs_right',\n",
        "    height=0.8, source=source, color=\"#2ca02c\",\n",
        "    legend_label=\"Fat\")\n",
        "\n",
        "    # Configure hover\n",
        "    custom_hover = HoverTool(\n",
        "    renderers=[protein_bar, carbs_bar, fat_bar],\n",
        "    mode='mouse',\n",
        "    tooltips=[\n",
        "        (\"Participant\", \"@participants\"),\n",
        "        (\"Age\",         \"@age years (@age_group)\"),\n",
        "        (\"Gender\",      \"@gender\"),\n",
        "        (\"Calories\",    \"@calories kcal\"),\n",
        "        (\"Protein\",     \"@protein%\"),\n",
        "        (\"Carbs\",       \"@carbs%\"),\n",
        "        (\"Fat\",         \"@fat%\")\n",
        "    ])\n",
        "\n",
        "    p.add_tools(custom_hover)\n",
        "\n",
        "    # Customize figure\n",
        "    p.xaxis.axis_label = \"Percentage of Total Calories (%)\"\n",
        "    p.yaxis.axis_label = \"Participant\"\n",
        "    p.legend.location = \"bottom_right\"\n",
        "    p.legend.orientation = \"horizontal\"\n",
        "    p.legend.click_policy = \"hide\"\n",
        "\n",
        "    # Add reference lines for recommended macronutrient ranges\n",
        "    p.add_layout(Legend(items=[\n",
        "        LegendItem(label=\"Recommended Protein: 10-35%\", renderers=[\n",
        "            p.line([10, 10], [0, len(participants)], line_color=\"blue\", line_dash=\"dashed\"),\n",
        "            p.line([35, 35], [0, len(participants)], line_color=\"blue\", line_dash=\"dashed\")\n",
        "        ]),\n",
        "        LegendItem(label=\"Recommended Carbs: 45-65%\", renderers=[\n",
        "            p.line([45, 45], [0, len(participants)], line_color=\"orange\", line_dash=\"dashed\"),\n",
        "            p.line([65, 65], [0, len(participants)], line_color=\"orange\", line_dash=\"dashed\")\n",
        "        ]),\n",
        "        LegendItem(label=\"Recommended Fat: 20-35%\", renderers=[\n",
        "            p.line([20, 20], [0, len(participants)], line_color=\"green\", line_dash=\"dashed\"),\n",
        "            p.line([35, 35], [0, len(participants)], line_color=\"green\", line_dash=\"dashed\")\n",
        "        ])\n",
        "    ]))\n",
        "\n",
        "    return p"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27352cc0-5396-417e-94cb-3c5cf2e45909",
      "metadata": {
        "id": "27352cc0-5396-417e-94cb-3c5cf2e45909"
      },
      "source": [
        "***Visualization 2: Macronutrient Distribution by Participant***\n",
        "\n",
        "This stacked horizontal bar chart shows, for each participant, the percentage of total calories obtained from protein (blue), carbohydrates (orange), and fat (green). Vertical dashed lines mark the recommended ranges: protein 10–35% (blue), carbs 45–65% (orange), and fat 20–35% (green). Hovering over any bar segment reveals the participant’s age (and age group), gender, total calories, and exact macronutrient percentages.\n",
        "\n",
        "***Key Insights***\n",
        "- Deficiencies in protein: Protein contributions range from 7.2% to 21.9%, with many individuals falling short of the recommended minimum of 10%.\n",
        "- Extremes of carbs: Only those with a carbohydrate proportion of 45% or more meet the recommended range of 23.8% to 63.6%. A 2-year-old boy notably reaches 63.6% carbohydrates.\n",
        "- Excess fat: There is a range of 22.1% to 54.8% fat intake; a 68-year-old woman's diet is particularly high at 54.8%, which is significantly more than the 35% top limit.\n",
        "- Few people are completely compliant: The majority of diets in this area are unbalanced, as only a tiny percentage of people have all three macronutrients completely within the advised ranges.\n",
        "\n",
        "***Implications***\n",
        "- Dietary patterns are highly variable, with many participants failing to meet one or more macronutrient recommendations.\n",
        "- Widespread low protein intake (< 10% of calories) suggests a need to increase protein sources in many diets.\n",
        "- In certain people, abnormally high percentages of carbohydrates (such as 63.6% in a 2-year-old) indicate an imbalance in their energy sources.\n",
        "- Moderation is advised since high fat intake (up to 54.8% in a 68-year-old) may increase cardiometabolic risk.\n",
        "- A small percentage of participants fall into each of the three suggested categories, underscoring the wide range of potential for individualized dietary advice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d526643-293e-4eee-9d3c-2062a0878367",
      "metadata": {
        "id": "6d526643-293e-4eee-9d3c-2062a0878367"
      },
      "outputs": [],
      "source": [
        "# VISUALIZATION 3: Waist-to-Hip Ratio vs. BMI with Dietary Information\n",
        "def create_waist_hip_bmi_plot():\n",
        "    # Filter data with complete body measurements\n",
        "    whr_data = data[['RIDAGEYR', 'RIAGENDR', 'BMXBMI', 'BMXWAIST', 'BMXHIP',\n",
        "                    'DR1TKCAL', 'DR1TPROT', 'DR1TCARB', 'DR1TTFAT']].copy()\n",
        "\n",
        "    # Drop rows with missing waist or hip measurements\n",
        "    whr_data = whr_data.dropna(subset=['BMXWAIST', 'BMXHIP', 'BMXBMI'])\n",
        "\n",
        "    # Calculate waist-to-hip ratio\n",
        "    whr_data['WHR'] = whr_data['BMXWAIST'] / whr_data['BMXHIP']\n",
        "\n",
        "    # Map gender codes to labels\n",
        "    whr_data['Gender'] = whr_data['RIAGENDR'].map({1: 'Male', 2: 'Female'})\n",
        "\n",
        "    # Create risk categories based on WHO guidelines\n",
        "    def whr_risk_category(row):\n",
        "        if row['Gender'] == 'Male':\n",
        "            if row['WHR'] < 0.9:\n",
        "                return 'Low Risk'\n",
        "            elif row['WHR'] < 1.0:\n",
        "                return 'Moderate Risk'\n",
        "            else:\n",
        "                return 'High Risk'\n",
        "        else:  # Female\n",
        "            if row['WHR'] < 0.8:\n",
        "                return 'Low Risk'\n",
        "            elif row['WHR'] < 0.85:\n",
        "                return 'Moderate Risk'\n",
        "            else:\n",
        "                return 'High Risk'\n",
        "\n",
        "    whr_data['Risk_Category'] = whr_data.apply(whr_risk_category, axis=1)\n",
        "\n",
        "    # Create BMI categories\n",
        "    def bmi_category(bmi):\n",
        "        if bmi < 18.5:\n",
        "            return 'Underweight'\n",
        "        elif bmi < 25:\n",
        "            return 'Normal'\n",
        "        elif bmi < 30:\n",
        "            return 'Overweight'\n",
        "        else:\n",
        "            return 'Obese'\n",
        "\n",
        "    whr_data['BMI_Category'] = whr_data['BMXBMI'].apply(bmi_category)\n",
        "\n",
        "    # Calculate diet quality if data is available\n",
        "    whr_data['Has_Diet_Data'] = ~whr_data['DR1TKCAL'].isna()\n",
        "    whr_data.loc[whr_data['Has_Diet_Data'], 'Calories'] = whr_data.loc[whr_data['Has_Diet_Data'], 'DR1TKCAL']\n",
        "\n",
        "    # Create a source for the plot\n",
        "    source = ColumnDataSource(data=dict(\n",
        "        bmi=whr_data['BMXBMI'],\n",
        "        whr=whr_data['WHR'],\n",
        "        waist=whr_data['BMXWAIST'],\n",
        "        hip=whr_data['BMXHIP'],\n",
        "        gender=whr_data['Gender'],\n",
        "        risk=whr_data['Risk_Category'],\n",
        "        bmi_cat=whr_data['BMI_Category'],\n",
        "        age=whr_data['RIDAGEYR'],\n",
        "        calories=whr_data['DR1TKCAL'],\n",
        "        has_diet=whr_data['Has_Diet_Data']\n",
        "    ))\n",
        "\n",
        "    # Create color mappers\n",
        "    risk_mapper = CategoricalColorMapper(\n",
        "        factors=['Low Risk', 'Moderate Risk', 'High Risk'],\n",
        "        palette=['#2ca02c', '#ff7f0e', '#d62728']\n",
        "    )\n",
        "\n",
        "    gender_mapper = CategoricalColorMapper(\n",
        "        factors=['Male', 'Female'],\n",
        "        palette=['#1f77b4', '#ff7f0e']\n",
        "    )\n",
        "\n",
        "    # Create the figure\n",
        "    p = figure(\n",
        "        title='Waist-to-Hip Ratio vs. BMI',\n",
        "        x_axis_label='BMI (kg/m²)',\n",
        "        y_axis_label='Waist-to-Hip Ratio',\n",
        "        width=800,\n",
        "        height=500,\n",
        "        tools='pan,box_select,zoom_in,zoom_out,reset,save'\n",
        "    )\n",
        "\n",
        "    # Add scatter points\n",
        "    scatter = p.circle(\n",
        "        'bmi', 'whr',\n",
        "        source=source,\n",
        "        size=12,\n",
        "        fill_color={'field': 'risk', 'transform': risk_mapper},\n",
        "        line_color={'field': 'gender', 'transform': gender_mapper},\n",
        "        line_width=2,\n",
        "        alpha=0.7\n",
        "    )\n",
        "\n",
        "    # Add reference lines\n",
        "    # Male WHR risk threshold\n",
        "    p.line([15, 50], [0.9, 0.9], line_color='blue', line_dash='dashed', line_width=2, legend_label='Male WHR Risk Threshold')\n",
        "    # Female WHR risk threshold\n",
        "    p.line([15, 50], [0.8, 0.8], line_color='orange', line_dash='dashed', line_width=2, legend_label='Female WHR Risk Threshold')\n",
        "    # BMI reference lines\n",
        "    p.line([25, 25], [0.6, 1.2], line_color='green', line_dash='dotted', line_width=2, legend_label='BMI = 25 (Overweight)')\n",
        "    p.line([30, 30], [0.6, 1.2], line_color='red', line_dash='dotted', line_width=2, legend_label='BMI = 30 (Obese)')\n",
        "\n",
        "    # Add hover tool\n",
        "    hover = HoverTool(\n",
        "        tooltips=[\n",
        "            ('Gender', '@gender'),\n",
        "            ('Age', '@age years'),\n",
        "            ('BMI', '@bmi{0.0} kg/m²'),\n",
        "            ('BMI Category', '@bmi_cat'),\n",
        "            ('WHR', '@whr{0.00}'),\n",
        "            ('Risk Category', '@risk'),\n",
        "            ('Waist', '@waist{0.0} cm'),\n",
        "            ('Hip', '@hip{0.0} cm'),\n",
        "            ('Calories', '@calories{0,0} kcal')\n",
        "        ],\n",
        "        renderers=[scatter]\n",
        "    )\n",
        "    p.add_tools(hover)\n",
        "\n",
        "    # Customize legend\n",
        "    p.legend.location = \"top_left\"\n",
        "    p.legend.click_policy = \"hide\"\n",
        "\n",
        "    return p"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be62681a-9fa2-46c0-8bbe-340ae96c1f74",
      "metadata": {
        "id": "be62681a-9fa2-46c0-8bbe-340ae96c1f74"
      },
      "source": [
        "***Visualization 3: Waist-to-Hip Ratio vs. BMI***\n",
        "\n",
        "Each participant's waist-to-hip ratio (WHR, y-axis) is shown against their BMI (x-axis) in this scatter plot. Points are shown by gender (blue = Male, orange = Female) and WHR risk group (green = Low Risk, orange = Moderate Risk, red = High Risk). WHR criteria are indicated by dashed horizontal lines (0.9 for men and 0.8 for women); BMI = 25 (overweight) and BMI = 30 (obesity) are indicated by dotted vertical lines. Age, BMI, WHR, risk category, body measurements, and daily caloric intake are displayed when hovered over.\n",
        "\n",
        "***Key Insights***\n",
        "- Overweight and obese people have high WHRs: Every person who meets WHR risk thresholds has a BMI of at least 25.\n",
        "- Gender disparities: While females cluster closer to their 0.8 threshold, male markers (blue outlines) frequently appear higher on the WHR axis—many guys exceed 0.9.\n",
        "- Divergent fat distribution: Some individuals with very high BMI (e.g., 64 kg/m²) remain in a Low Risk WHR category, illustrating different patterns of central adiposity.\n",
        "- Complementary measurements: By identifying those who have excess abdominal fat, WHR refines risk, whereas BMI alone would classify many as obese.\n",
        "\n",
        "***Implications***\n",
        "- Individuals who have a BMI of 30 or above with a WHR above the limits are at a higher risk of cardiometabolic problems and ought to receive priority attention.\n",
        "- Despite having a high body mass, WHR identifies people with a healthy fat distribution, adding nuance beyond BMI.\n",
        "- The interactive hover that connects WHR/BMI and caloric intake reveals that people with the highest anthropometric risk tend to consume more calories, which suggests nutritional counseling targets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7f3bb57-dd66-4739-8de9-cd44ec1234a0",
      "metadata": {
        "id": "d7f3bb57-dd66-4739-8de9-cd44ec1234a0"
      },
      "outputs": [],
      "source": [
        "# VISUALIZATION 4: Interactive Nutritional Intake Analysis\n",
        "def create_nutrient_analysis():\n",
        "    # Select nutritional columns of interest\n",
        "    nutrient_cols = [\n",
        "        'DR1TKCAL', 'DR1TPROT', 'DR1TCARB', 'DR1TFIBE', 'DR1TSUGR',\n",
        "        'DR1TTFAT', 'DR1TSFAT', 'DR1TMFAT', 'DR1TPFAT', 'DR1TCHOL',\n",
        "        'DR1TSODI', 'DR1TPOTA', 'DR1TCALC', 'DR1TIRON', 'DR1TZINC'\n",
        "    ]\n",
        "\n",
        "    # Filter participants with complete nutritional data\n",
        "    nutrient_data = data[['SEQN', 'RIDAGEYR', 'RIAGENDR'] + nutrient_cols].dropna(subset=['DR1TKCAL'])\n",
        "\n",
        "    # Map gender codes to labels\n",
        "    nutrient_data['Gender'] = nutrient_data['RIAGENDR'].map({1: 'Male', 2: 'Female'})\n",
        "\n",
        "    # Create participant ID\n",
        "    nutrient_data['Participant_ID'] = nutrient_data['SEQN'].astype(str)\n",
        "\n",
        "    # Create readable nutrient names mapping\n",
        "    nutrient_names = {\n",
        "        'DR1TKCAL': 'Calories (kcal)',\n",
        "        'DR1TPROT': 'Protein (g)',\n",
        "        'DR1TCARB': 'Carbohydrates (g)',\n",
        "        'DR1TFIBE': 'Fiber (g)',\n",
        "        'DR1TSUGR': 'Sugar (g)',\n",
        "        'DR1TTFAT': 'Total Fat (g)',\n",
        "        'DR1TSFAT': 'Saturated Fat (g)',\n",
        "        'DR1TMFAT': 'Monounsaturated Fat (g)',\n",
        "        'DR1TPFAT': 'Polyunsaturated Fat (g)',\n",
        "        'DR1TCHOL': 'Cholesterol (mg)',\n",
        "        'DR1TSODI': 'Sodium (mg)',\n",
        "        'DR1TPOTA': 'Potassium (mg)',\n",
        "        'DR1TCALC': 'Calcium (mg)',\n",
        "        'DR1TIRON': 'Iron (mg)',\n",
        "        'DR1TZINC': 'Zinc (mg)'\n",
        "    }\n",
        "\n",
        "    # Calculate reference values (simplified - would be more accurate with gender/age specific values)\n",
        "    reference_values = {\n",
        "        'DR1TKCAL': 2000,        # Base reference\n",
        "        'DR1TPROT': 50,          # g/day\n",
        "        'DR1TCARB': 275,         # g/day\n",
        "        'DR1TFIBE': 25,          # g/day\n",
        "        'DR1TSUGR': 50,          # g/day\n",
        "        'DR1TTFAT': 65,          # g/day\n",
        "        'DR1TSFAT': 20,          # g/day\n",
        "        'DR1TMFAT': 25,          # g/day\n",
        "        'DR1TPFAT': 25,          # g/day\n",
        "        'DR1TCHOL': 300,         # mg/day\n",
        "        'DR1TSODI': 2300,        # mg/day\n",
        "        'DR1TPOTA': 4700,        # mg/day\n",
        "        'DR1TCALC': 1000,        # mg/day\n",
        "        'DR1TIRON': 18,          # mg/day\n",
        "        'DR1TZINC': 11           # mg/day\n",
        "    }\n",
        "\n",
        "    # Create source for the initial nutrient (calories)\n",
        "    initial_nutrient = 'DR1TKCAL'\n",
        "    source = ColumnDataSource(data=dict(\n",
        "        participants=nutrient_data['Participant_ID'].tolist(),\n",
        "        values=nutrient_data[initial_nutrient].tolist(),\n",
        "        gender=nutrient_data['Gender'].tolist(),\n",
        "        age=nutrient_data['RIDAGEYR'].tolist()\n",
        "    ))\n",
        "\n",
        "    # Create figure\n",
        "    p = figure(\n",
        "        y_range=source.data['participants'],\n",
        "        title=f\"Nutrient Intake: {nutrient_names[initial_nutrient]}\",\n",
        "        width=800,\n",
        "        height=400,\n",
        "        x_axis_label=nutrient_names[initial_nutrient],\n",
        "        tools=\"pan,box_zoom,reset,save\"\n",
        "    )\n",
        "\n",
        "    # Add horizontal bars\n",
        "    bars = p.hbar(\n",
        "        y='participants', right='values', height=0.9, source=source,\n",
        "        color=factor_cmap('gender', ['#1f77b4','#ff7f0e'], ['Male','Female']),\n",
        "        line_color='black', line_width=1)\n",
        "\n",
        "    # Add reference line\n",
        "    ref_value = reference_values[initial_nutrient]\n",
        "    ref_line = p.line([ref_value, ref_value],\n",
        "                      [0, len(nutrient_data)], line_color=\"red\", line_dash=\"dashed\", line_width=2)\n",
        "\n",
        "    # Add reference line label\n",
        "    ref_label = p.text(x=[ref_value * 1.05], y=[len(nutrient_data) * 0.9],\n",
        "                      text=['Reference Value'], text_color=\"red\")\n",
        "\n",
        "    # Configure hover\n",
        "    hover = HoverTool(\n",
        "        renderers=[bars],\n",
        "        tooltips=[\n",
        "            (\"Participant\", \"@participants\"),\n",
        "            (\"Age\",         \"@age years\"),\n",
        "            (\"Gender\",      \"@gender\"),\n",
        "            (nutrient_names[initial_nutrient], \"@values{0,0.0}\")],\n",
        "        mode='mouse')\n",
        "    p.add_tools(hover)\n",
        "\n",
        "    # Customize figure\n",
        "    p.xaxis.axis_label = nutrient_names[initial_nutrient]\n",
        "    p.yaxis.axis_label = \"Participant\"\n",
        "\n",
        "    # Create nutrient selector\n",
        "    nutrient_select = Select(\n",
        "        title=\"Select Nutrient:\",\n",
        "        value=nutrient_names[initial_nutrient],\n",
        "        options=list(nutrient_names.values())\n",
        "    )\n",
        "\n",
        "    display_to_code = {v: k for k, v in nutrient_names.items()}\n",
        "\n",
        "    # JavaScript callback to update plot when nutrient is changed\n",
        "    callback = CustomJS(\n",
        "        args=dict(\n",
        "            source=source,\n",
        "            p=p,\n",
        "            xaxis=p.xaxis[0],\n",
        "            ref_line=ref_line,\n",
        "            ref_label=ref_label,\n",
        "            nutrient_data=nutrient_data.to_dict('list'),\n",
        "            reference_values=reference_values,\n",
        "            hover=hover,\n",
        "            display_to_code=display_to_code\n",
        "        ),\n",
        "        code=\"\"\"\n",
        "            // 1) Figure out the selection\n",
        "            const sel_name = cb_obj.value;\n",
        "            const sel_code = display_to_code[sel_name];\n",
        "            const rv     = reference_values[sel_code];\n",
        "\n",
        "            // 2) Swap in the new bar values\n",
        "            source.data['values'] = nutrient_data[sel_code];\n",
        "            source.change.emit();\n",
        "\n",
        "            // 3) Rebuild the hover-tooltips array completely\n",
        "            const new_tips = [\n",
        "              [\"Participant\", \"@participants\"],\n",
        "              [\"Age\",         \"@age years\"],\n",
        "              [\"Gender\",      \"@gender\"],\n",
        "              [ sel_name, \"@values{0,0.0}\" ]\n",
        "            ];\n",
        "            hover.setv({ tooltips: new_tips });\n",
        "\n",
        "            // 4) Update title and axis label\n",
        "            p.title.text = \"Nutrient Intake: \" + sel_name;\n",
        "            xaxis.setv({ axis_label: sel_name });\n",
        "            xaxis.change.emit();\n",
        "\n",
        "            // 5) Move the dashed reference line\n",
        "            ref_line.setv({ xs: [rv, rv] });\n",
        "\n",
        "            // 6) Reposition the \"Reference Value\" text\n",
        "            const ds = ref_label.data_source;\n",
        "            ds.data['x'] = [ rv * 1.05 ];\n",
        "            ds.change.emit();\n",
        "\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    nutrient_select.js_on_change('value', callback)\n",
        "\n",
        "\n",
        "    # Create layout\n",
        "    layout = column(nutrient_select, p)\n",
        "\n",
        "    return layout"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f040317-c547-484b-8c56-b90336aec084",
      "metadata": {
        "id": "4f040317-c547-484b-8c56-b90336aec084"
      },
      "source": [
        "***Visualization 4: Interactive Nutrient Analysis***\n",
        "\n",
        "Using the dropdown menu, you may select any nutrient in this horizontal bar chart, including vitamins, minerals, calories, and macronutrients. One participant's intake is represented by each bar. The suggested daily goal for the chosen nutrient is indicated by a red dashed reference line.\n",
        "\n",
        "***Key Insights***\n",
        "- Large variety of calories: Energy consumption ranges from 1,200 to 3,850 kcal per day, with the 2,000 kcal recommended at its center.\n",
        "- Extensive lack of fiber: Most participants don't meet the recommended daily intake of 25 grams of fiber.\n",
        "- High fluctuation in sugar levels: Consumption of sugar varies from about 38 g to about 228 g, with many people going over the 50 g limit.\n",
        "- Frequent overconsumption of sodium: Many exceed the recommended daily intake of 2,300 mg of sodium.\n",
        "- Protein adequacy with outliers. Most meet the 50 g/day protein reference, but intake varies widely (29–132 g).\n",
        "\n",
        "***Implications***\n",
        "- Static charts fail to identify nutrient-specific imbalances, but interactive selection does.\n",
        "- Participants who require attention for sodium, sugar, or fiber are immediately identified by reference lines.\n",
        "- This tool facilitates the quick detection of outliers and directs nutrient-specific individualized dietary recommendations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f03007f-2e99-432d-9174-6cbd50dd910a",
      "metadata": {
        "id": "7f03007f-2e99-432d-9174-6cbd50dd910a"
      },
      "outputs": [],
      "source": [
        "# VISUALIZATION 5: Health Metrics and Dietary Pattern Dashboard\n",
        "def create_health_diet_dashboard():\n",
        "    # Prepare data for dashboard\n",
        "    dashboard_data = data[['SEQN', 'RIDAGEYR', 'RIAGENDR', 'BMXBMI', 'BMXWT',\n",
        "                          'BMXHT', 'BMXWAIST', 'BMXHIP', 'LBXTC',\n",
        "                          'DR1TKCAL', 'DR1TPROT', 'DR1TCARB', 'DR1TFIBE',\n",
        "                          'DR1TSUGR', 'DR1TTFAT', 'DR1TSODI']].copy()\n",
        "\n",
        "    # Map gender codes to labels\n",
        "    dashboard_data['Gender'] = dashboard_data['RIAGENDR'].map({1: 'Male', 2: 'Female'})\n",
        "\n",
        "    # Calculate waist-to-hip ratio if data is available\n",
        "    mask = (~dashboard_data['BMXWAIST'].isna()) & (~dashboard_data['BMXHIP'].isna())\n",
        "    dashboard_data.loc[mask, 'WHR'] = dashboard_data.loc[mask, 'BMXWAIST'] / dashboard_data.loc[mask, 'BMXHIP']\n",
        "\n",
        "    # Create participant ID\n",
        "    dashboard_data['Participant_ID'] = ['P' + str(i+1) for i in range(len(dashboard_data))]\n",
        "\n",
        "    # Create BMI categories\n",
        "    def bmi_category(bmi):\n",
        "        if pd.isna(bmi):\n",
        "            return 'Unknown'\n",
        "        elif bmi < 18.5:\n",
        "            return 'Underweight'\n",
        "        elif bmi < 25:\n",
        "            return 'Normal'\n",
        "        elif bmi < 30:\n",
        "            return 'Overweight'\n",
        "        else:\n",
        "            return 'Obese'\n",
        "\n",
        "    dashboard_data['BMI_Category'] = dashboard_data['BMXBMI'].apply(bmi_category)\n",
        "\n",
        "    # Create WHR risk categories\n",
        "    def whr_risk(row):\n",
        "        if pd.isna(row['WHR']):\n",
        "            return 'Unknown'\n",
        "        elif row['Gender'] == 'Male':\n",
        "            if row['WHR'] < 0.9:\n",
        "                return 'Low Risk'\n",
        "            elif row['WHR'] < 1.0:\n",
        "                return 'Moderate Risk'\n",
        "            else:\n",
        "                return 'High Risk'\n",
        "        else:\n",
        "            if row['WHR'] < 0.8:\n",
        "                return 'Low Risk'\n",
        "            elif row['WHR'] < 0.85:\n",
        "                return 'Moderate Risk'\n",
        "            else:\n",
        "                return 'High Risk'\n",
        "\n",
        "    dashboard_data['WHR_Risk'] = dashboard_data.apply(whr_risk, axis=1)\n",
        "\n",
        "    # Calculate nutritional metrics if available\n",
        "    mask = ~dashboard_data['DR1TKCAL'].isna()\n",
        "    if mask.any():\n",
        "        # Calculate protein percentage\n",
        "        dashboard_data.loc[mask, 'Protein_pct'] = dashboard_data.loc[mask, 'DR1TPROT'] * 4 / dashboard_data.loc[mask, 'DR1TKCAL'] * 100\n",
        "\n",
        "        # Calculate carb percentage\n",
        "        dashboard_data.loc[mask, 'Carb_pct'] = dashboard_data.loc[mask, 'DR1TCARB'] * 4 / dashboard_data.loc[mask, 'DR1TKCAL'] * 100\n",
        "\n",
        "        # Calculate fat percentage\n",
        "        dashboard_data.loc[mask, 'Fat_pct'] = dashboard_data.loc[mask, 'DR1TTFAT'] * 9 / dashboard_data.loc[mask, 'DR1TKCAL'] * 100\n",
        "\n",
        "        # Calculate sugar as percentage of carbs\n",
        "        mask2 = (~dashboard_data['DR1TSUGR'].isna()) & (~dashboard_data['DR1TCARB'].isna())\n",
        "        dashboard_data.loc[mask2, 'Sugar_carb_ratio'] = dashboard_data.loc[mask2, 'DR1TSUGR'] / dashboard_data.loc[mask2, 'DR1TCARB'] * 100\n",
        "\n",
        "    # ----- Create interactive selectors and plots -----\n",
        "\n",
        "    # Create participant selector\n",
        "    participant_ids = dashboard_data['Participant_ID'].tolist()\n",
        "    participant_select = Select(title=\"Select Participant:\", value=participant_ids[0], options=participant_ids)\n",
        "\n",
        "    # Filter for the first participant initially\n",
        "    initial_participant = dashboard_data[dashboard_data['Participant_ID'] == participant_ids[0]].iloc[0]\n",
        "\n",
        "    # ----- Participant Info Panel -----\n",
        "\n",
        "    # Create table for participant info\n",
        "    participant_source = ColumnDataSource(data=dict(\n",
        "        metrics=['Age', 'Gender', 'BMI', 'BMI Category', 'Height', 'Weight',\n",
        "                'Waist Circumference', 'Hip Circumference', 'Waist-Hip Ratio', 'WHR Risk',\n",
        "                'Total Cholesterol'],\n",
        "        values=[\n",
        "            initial_participant['RIDAGEYR'] if not pd.isna(initial_participant['RIDAGEYR']) else 'N/A',\n",
        "            initial_participant['Gender'],\n",
        "            f\"{initial_participant['BMXBMI']:.1f}\" if not pd.isna(initial_participant['BMXBMI']) else 'N/A',\n",
        "            initial_participant['BMI_Category'],\n",
        "            f\"{initial_participant['BMXHT']:.1f} cm\" if not pd.isna(initial_participant['BMXHT']) else 'N/A',\n",
        "            f\"{initial_participant['BMXWT']:.1f} kg\" if not pd.isna(initial_participant['BMXWT']) else 'N/A',\n",
        "            f\"{initial_participant['BMXWAIST']:.1f} cm\" if not pd.isna(initial_participant['BMXWAIST']) else 'N/A',\n",
        "            f\"{initial_participant['BMXHIP']:.1f} cm\" if not pd.isna(initial_participant['BMXHIP']) else 'N/A',\n",
        "            f\"{initial_participant['WHR']:.2f}\" if not pd.isna(initial_participant.get('WHR')) else 'N/A',\n",
        "            initial_participant['WHR_Risk'] if not pd.isna(initial_participant.get('WHR_Risk')) else 'N/A',\n",
        "            f\"{initial_participant['LBXTC']:.0f} mg/dL\" if not pd.isna(initial_participant['LBXTC']) else 'N/A'\n",
        "        ]\n",
        "    ))\n",
        "\n",
        "    # Create table columns\n",
        "    columns = [\n",
        "        TableColumn(field=\"metrics\", title=\"Health Metric\"),\n",
        "        TableColumn(field=\"values\", title=\"Value\")\n",
        "    ]\n",
        "\n",
        "    # Create data table\n",
        "    info_table = DataTable(source=participant_source, columns=columns,\n",
        "                         width=400, height=300, index_position=None)\n",
        "\n",
        "    # ----- Nutritional Info Panel -----\n",
        "\n",
        "    # Create source for nutrition data\n",
        "    nutrition_source = ColumnDataSource(data=dict(\n",
        "        metrics=['Total Calories', 'Protein', 'Carbohydrates', 'Fiber', 'Sugar',\n",
        "                'Total Fat', 'Sodium', 'Protein % of Calories', 'Carbs % of Calories',\n",
        "                'Fat % of Calories', 'Sugar % of Carbs'],\n",
        "        values=[\n",
        "            f\"{initial_participant['DR1TKCAL']:.0f} kcal\" if not pd.isna(initial_participant['DR1TKCAL']) else 'N/A',\n",
        "            f\"{initial_participant['DR1TPROT']:.1f} g\" if not pd.isna(initial_participant['DR1TPROT']) else 'N/A',\n",
        "            f\"{initial_participant['DR1TCARB']:.1f} g\" if not pd.isna(initial_participant['DR1TCARB']) else 'N/A',\n",
        "            f\"{initial_participant['DR1TFIBE']:.1f} g\" if not pd.isna(initial_participant['DR1TFIBE']) else 'N/A',\n",
        "            f\"{initial_participant['DR1TSUGR']:.1f} g\" if not pd.isna(initial_participant['DR1TSUGR']) else 'N/A',\n",
        "            f\"{initial_participant['DR1TTFAT']:.1f} g\" if not pd.isna(initial_participant['DR1TTFAT']) else 'N/A',\n",
        "            f\"{initial_participant['DR1TSODI']:.0f} mg\" if not pd.isna(initial_participant['DR1TSODI']) else 'N/A',\n",
        "            f\"{initial_participant.get('Protein_pct', 'N/A'):.1f}%\" if not pd.isna(initial_participant.get('Protein_pct')) else 'N/A',\n",
        "            f\"{initial_participant.get('Carb_pct', 'N/A'):.1f}%\" if not pd.isna(initial_participant.get('Carb_pct')) else 'N/A',\n",
        "            f\"{initial_participant.get('Fat_pct', 'N/A'):.1f}%\" if not pd.isna(initial_participant.get('Fat_pct')) else 'N/A',\n",
        "            f\"{initial_participant.get('Sugar_carb_ratio', 'N/A'):.1f}%\" if not pd.isna(initial_participant.get('Sugar_carb_ratio')) else 'N/A'\n",
        "        ]\n",
        "    ))\n",
        "\n",
        "    # Create nutrition table columns\n",
        "    nutrition_columns = [\n",
        "        TableColumn(field=\"metrics\", title=\"Nutrient\"),\n",
        "        TableColumn(field=\"values\", title=\"Value\")\n",
        "    ]\n",
        "\n",
        "    # Create nutrition data table\n",
        "    nutrition_table = DataTable(source=nutrition_source, columns=nutrition_columns,\n",
        "                             width=400, height=300, index_position=None)\n",
        "\n",
        "    # ----- JavaScript callback to update all visualizations when a new participant is selected -----\n",
        "\n",
        "    callback = CustomJS(args=dict(\n",
        "        participant_source=participant_source,\n",
        "        nutrition_source=nutrition_source,\n",
        "        dashboard_data=dashboard_data.to_dict('records'),\n",
        "        participant_ids=participant_ids\n",
        "    ), code=\"\"\"\n",
        "        // Get the selected participant ID\n",
        "        const selected_id = cb_obj.value;\n",
        "\n",
        "        // Find the participant data\n",
        "        const participant = dashboard_data.find(p => p.Participant_ID === selected_id);\n",
        "\n",
        "        if (participant) {\n",
        "            // Update participant info table\n",
        "            participant_source.data.values = [\n",
        "                participant.RIDAGEYR !== null ? participant.RIDAGEYR : 'N/A',\n",
        "                participant.Gender,\n",
        "                participant.BMXBMI !== null ? participant.BMXBMI.toFixed(1) : 'N/A',\n",
        "                participant.BMI_Category,\n",
        "                participant.BMXHT !== null ? participant.BMXHT.toFixed(1) + ' cm' : 'N/A',\n",
        "                participant.BMXWT !== null ? participant.BMXWT.toFixed(1) + ' kg' : 'N/A',\n",
        "                participant.BMXWAIST !== null ? participant.BMXWAIST.toFixed(1) + ' cm' : 'N/A',\n",
        "                participant.BMXHIP !== null ? participant.BMXHIP.toFixed(1) + ' cm' : 'N/A',\n",
        "                participant.WHR !== null ? participant.WHR.toFixed(2) : 'N/A',\n",
        "                participant.WHR_Risk || 'N/A',\n",
        "                participant.LBXTC !== null ? participant.LBXTC.toFixed(0) + ' mg/dL' : 'N/A'\n",
        "            ];\n",
        "\n",
        "            // Update nutrition info table\n",
        "            nutrition_source.data.values = [\n",
        "                participant.DR1TKCAL !== null ? participant.DR1TKCAL.toFixed(0) + ' kcal' : 'N/A',\n",
        "                participant.DR1TPROT !== null ? participant.DR1TPROT.toFixed(1) + ' g' : 'N/A',\n",
        "                participant.DR1TCARB !== null ? participant.DR1TCARB.toFixed(1) + ' g' : 'N/A',\n",
        "                participant.DR1TFIBE !== null ? participant.DR1TFIBE.toFixed(1) + ' g' : 'N/A',\n",
        "                participant.DR1TSUGR !== null ? participant.DR1TSUGR.toFixed(1) + ' g' : 'N/A',\n",
        "                participant.DR1TTFAT !== null ? participant.DR1TTFAT.toFixed(1) + ' g' : 'N/A',\n",
        "                participant.DR1TSODI !== null ? participant.DR1TSODI.toFixed(0) + ' mg' : 'N/A',\n",
        "                participant.Protein_pct !== null ? participant.Protein_pct.toFixed(1) + '%' : 'N/A',\n",
        "                participant.Carb_pct !== null ? participant.Carb_pct.toFixed(1) + '%' : 'N/A',\n",
        "                participant.Fat_pct !== null ? participant.Fat_pct.toFixed(1) + '%' : 'N/A',\n",
        "                participant.Sugar_carb_ratio !== null ? participant.Sugar_carb_ratio.toFixed(1) + '%' : 'N/A'\n",
        "            ];\n",
        "\n",
        "            // Emit changes to update tables\n",
        "            participant_source.change.emit();\n",
        "            nutrition_source.change.emit();\n",
        "        }\n",
        "    \"\"\")\n",
        "\n",
        "    # Attach callback to participant selector\n",
        "    participant_select.js_on_change('value', callback)\n",
        "\n",
        "    # Create dashboard layout\n",
        "    dashboard = column(\n",
        "        participant_select,\n",
        "        row(\n",
        "            column(info_table, nutrition_table)\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    return dashboard"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d305cca-ac89-4c61-89c7-ba36fc70e020",
      "metadata": {
        "id": "7d305cca-ac89-4c61-89c7-ba36fc70e020"
      },
      "source": [
        "***Visualization 5: Health Metrics and Dietary Pattern Dashboard***\n",
        "\n",
        "Each participant's dietary profile (calories, macronutrients, fiber, sugar, sodium, and percent breakdowns) and critical health metrics (age, gender, BMI & category, height/weight, waist & hip measures, WHR & risk, and cholesterol) are shown side by side in this interactive dashboard.\n",
        "\n",
        "***Key Insights***\n",
        "- BMI is in line with central obesity: People with a BMI of 46.0, for example, are classified as obese. They also have greater cholesterol, a larger waist circumference, and an increased risk of WHR.\n",
        "- Severe nutritional imbalances: The participant with the highest BMI (46.0) consumes 107 g of sugar and 35.1% of calories from fat, whereas the person with the second-highest BMI (42.6) logs 3,849 kcal and 228 g of sugar.\n",
        "- BMI and WHR risk are similar: The majority of people who are categorized as \"High Risk\" by WHR also had BMIs that fall into the overweight/obese range.\n",
        "- Typical excess sodium: The recommended sodium intake of 2,300 mg per day is often exceeded, even by people with moderate BMI.\n",
        "- Data gaps: A number of high-risk people had incomplete dietary records (designated as \"NaN\"), indicating areas that require better data collection.\n",
        "\n",
        "***Implications***\n",
        "- Participants with elevated cardiometabolic risk based on their anthropometric and nutritional profiles can be quickly identified with a comprehensive dashboard.\n",
        "- Correlating diet patterns with health metrics uncovers potential nutritional drivers of obesity and central adiposity.\n",
        "- Targeted dietary counseling is supported by the instantaneous visibility of outlier cases (such as excessive consumption of sugar or fat).\n",
        "- When combined, WHR and BMI improve risk categorization beyond what can be achieved with just one measure.\n",
        "- The identification of missing dietary data emphasizes how crucial comprehensive recall collection is to precise risk assessment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c11a585d-b11c-435e-83db-cf8c36f52652",
      "metadata": {
        "id": "c11a585d-b11c-435e-83db-cf8c36f52652",
        "outputId": "743a8b58-4a15-433d-d0b5-5b66bdf61872"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<a href='./health_data_visualizations.html' target='_blank'>🚀 View your dashboard</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create all visualizations and organize them into tabs\n",
        "def create_visualization_tabs():\n",
        "    # Create each visualization\n",
        "    bmi_plot = create_bmi_scatter()\n",
        "    macro_plot = create_macronutrient_chart()\n",
        "    whr_plot = create_waist_hip_bmi_plot()\n",
        "    nutrient_analysis = create_nutrient_analysis()\n",
        "    dashboard = create_health_diet_dashboard()\n",
        "\n",
        "    # Create a simple layout with all visualizations\n",
        "    from bokeh.layouts import column\n",
        "\n",
        "    # Add header text for each visualization\n",
        "    from bokeh.models import Div\n",
        "\n",
        "    bmi_header = Div(text=\"<h2>BMI Distribution by Age and Gender</h2>\")\n",
        "    macro_header = Div(text=\"<h2>Macronutrient Distribution by Participant</h2>\")\n",
        "    whr_header = Div(text=\"<h2>Waist-to-Hip Ratio vs. BMI</h2>\")\n",
        "    nutrient_header = Div(text=\"<h2>Interactive Nutrient Analysis</h2>\")\n",
        "    dashboard_header = Div(text=\"<h2>Health Metrics and Dietary Pattern Dashboard</h2>\")\n",
        "\n",
        "    # Create a layout with all visualizations\n",
        "    layout = column(\n",
        "        bmi_header, bmi_plot,\n",
        "        macro_header, macro_plot,\n",
        "        whr_header, whr_plot,\n",
        "        nutrient_header, nutrient_analysis,\n",
        "        dashboard_header, dashboard,\n",
        "        sizing_mode=\"stretch_width\"\n",
        "    )\n",
        "\n",
        "    return layout\n",
        "\n",
        "# Main function to run everything\n",
        "def main():\n",
        "    # Create visualization layout\n",
        "    visualization_layout = create_visualization_tabs()\n",
        "\n",
        "    # Output to file\n",
        "    output_file(\"health_data_visualizations.html\")\n",
        "\n",
        "    # Save the visualizations to file\n",
        "    save(visualization_layout)\n",
        "\n",
        "    from IPython.display import HTML, display\n",
        "\n",
        "    # assumes the notebook server is serving the current working directory\n",
        "    url = \"./health_data_visualizations.html\"\n",
        "    display(HTML(f\"<a href='{url}' target='_blank'>🚀 View your dashboard</a>\"))\n",
        "\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1ec003b-fd88-4f2a-95b7-e725fdc93b39",
      "metadata": {
        "id": "b1ec003b-fd88-4f2a-95b7-e725fdc93b39"
      },
      "source": [
        "***1.3 Overall Insights from the Data Analysis***\n",
        "\n",
        "With the majority of participants being overweight or obese by BMI and many exceeding appropriate waist-to-hip ratios, the group exhibits a significant burden of excess weight and central adiposity. The necessity of focused intervention is highlighted by a noteworthy subset that demonstrates several cardiometabolic risk markers, including elevated WHR, elevated cholesterol, and high BMI.\n",
        "\n",
        "These hazards are exacerbated by dietary trends. Unbalances in macronutrients are common, protein is typically inadequate, and percentages of fat and carbohydrates usually fall outside of advised ranges. Fiber consumption hardly ever reaches the 25 g/day target, and added-sugar intake frequently exceeds 50 g/day (with extremes exceeding 200 g). Nutrient quality is still below ideal even when caloric intake is sufficient or excessive.\n",
        "\n",
        "Both young and old exhibit extreme diets, and males tend toward higher WHR, while females show wider fluctuation in BMI. These hazardous trends are age- and gender-specific. Interactive dashboards that connect individual metrics and nutrient intake facilitate the quick detection of outliers (such as teenagers who consume too much sugar or elderly who consume a lot of fat) and promote individualized dietary advice aimed at reducing added sugars, increasing fiber, and rebalancing macronutrients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be819df2-ceea-4517-b6fc-1c000b11aee7",
      "metadata": {
        "id": "be819df2-ceea-4517-b6fc-1c000b11aee7",
        "outputId": "cea40150-9af1-4b53-fdb7-ab3c009bd6fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CV AUC: 0.972\n",
            "Best params: {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "\n",
            "--- Test set performance (threshold = 0.50) ---\n",
            "ROC AUC: 0.973\n",
            "Confusion Matrix:\n",
            " [[405  30]\n",
            " [ 99 894]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.93      0.86       435\n",
            "           1       0.97      0.90      0.93       993\n",
            "\n",
            "    accuracy                           0.91      1428\n",
            "   macro avg       0.89      0.92      0.90      1428\n",
            "weighted avg       0.92      0.91      0.91      1428\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#-------------Logistic Regression-----------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
        "\n",
        "# 1. Load data\n",
        "df = pd.read_csv(r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\NHANES_master_imputed.csv\")\n",
        "\n",
        "# 2. Create target\n",
        "df['Overweight_Obese'] = (df['BMXBMI'] >= 25).astype(int)\n",
        "\n",
        "# 3. Compute proxy features\n",
        "df['WHR'] = df['BMXWAIST'] / df['BMXHIP']\n",
        "\n",
        "# 4. Define feature list *without* BMXBMI\n",
        "features = [\n",
        "    'RIDAGEYR',      # age\n",
        "    'RIAGENDR',      # gender\n",
        "    'BMXWAIST',      # waist circumference\n",
        "    'BMXHIP',        # hip circumference\n",
        "    'WHR',           # waist-to-hip ratio\n",
        "    'LBXTC',         # total cholesterol\n",
        "    'DR1TKCAL',      # calories\n",
        "    'DR1TPROT',      # protein\n",
        "    'DR1TCARB',      # carbs\n",
        "    'DR1TSUGR',      # sugar\n",
        "    'DR1TFIBE',      # fiber\n",
        "    'DR1TTFAT',      # total fat\n",
        "    'DR1TSODI'       # sodium\n",
        "]\n",
        "\n",
        "# 5. Drop rows with missing in any of the chosen features or target\n",
        "data = df[features + ['Overweight_Obese']].dropna()\n",
        "\n",
        "X = data[features]\n",
        "y = data['Overweight_Obese']\n",
        "\n",
        "# 6. Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# 7. One-hot encode gender\n",
        "X_train = pd.get_dummies(X_train, columns=['RIAGENDR'], drop_first=True)\n",
        "X_test  = pd.get_dummies(X_test,  columns=['RIAGENDR'], drop_first=True)\n",
        "\n",
        "# 8. Hyperparameter tuning with cross-validation\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['liblinear'],\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "grid = GridSearchCV(\n",
        "    LogisticRegression(random_state=42),\n",
        "    param_grid,\n",
        "    scoring='roc_auc',\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best CV AUC: {grid.best_score_:.3f}\")\n",
        "print(f\"Best params: {grid.best_params_}\")\n",
        "\n",
        "# 9. Evaluate on test set\n",
        "best_lr = grid.best_estimator_\n",
        "y_prob = best_lr.predict_proba(X_test)[:,1]\n",
        "y_pred = (y_prob >= 0.50).astype(int)\n",
        "\n",
        "print(\"\\n--- Test set performance (threshold = 0.50) ---\")\n",
        "print(f\"ROC AUC: {roc_auc_score(y_test, y_prob):.3f}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67af6f5c-bb62-442f-b71d-689b5c09303f",
      "metadata": {
        "id": "67af6f5c-bb62-442f-b71d-689b5c09303f",
        "outputId": "62b47226-ae1a-4f81-fdd9-6d83f53c1947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best CV AUC: 0.969\n",
            "Best params: {'class_weight': 'balanced', 'max_depth': 15, 'n_estimators': 300}\n",
            "\n",
            "--- Test set performance (threshold = 0.50) ---\n",
            "ROC AUC: 0.972\n",
            "Confusion Matrix:\n",
            " [[371  64]\n",
            " [ 53 940]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.85      0.86       435\n",
            "           1       0.94      0.95      0.94       993\n",
            "\n",
            "    accuracy                           0.92      1428\n",
            "   macro avg       0.91      0.90      0.90      1428\n",
            "weighted avg       0.92      0.92      0.92      1428\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#-----------Random Forest classifier----------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
        "\n",
        "# 1. Load data\n",
        "df = pd.read_csv(r\"C:\\Users\\User\\OneDrive\\Desktop\\T1- 2025\\SIT731-Data Wrangling\\1.7HD\\NHANES_master_imputed.csv\")\n",
        "\n",
        "# 2. Create binary target\n",
        "df['Overweight_Obese'] = (df['BMXBMI'] >= 25).astype(int)\n",
        "\n",
        "# 3. Compute WHR proxy feature\n",
        "df['WHR'] = df['BMXWAIST'] / df['BMXHIP']\n",
        "\n",
        "# 4. Define features (same as LR)\n",
        "features = [\n",
        "    'RIDAGEYR',      # age\n",
        "    'RIAGENDR',      # gender\n",
        "    'BMXWAIST',      # waist\n",
        "    'BMXHIP',        # hip\n",
        "    'WHR',           # waist-to-hip\n",
        "    'LBXTC',         # cholesterol\n",
        "    'DR1TKCAL',      # calories\n",
        "    'DR1TPROT',      # protein\n",
        "    'DR1TCARB',      # carbs\n",
        "    'DR1TSUGR',      # sugar\n",
        "    'DR1TFIBE',      # fiber\n",
        "    'DR1TTFAT',      # total fat\n",
        "    'DR1TSODI'       # sodium\n",
        "]\n",
        "\n",
        "# 5. Drop any rows with missing features/target\n",
        "data = df[features + ['Overweight_Obese']].dropna()\n",
        "X = data[features]\n",
        "y = data['Overweight_Obese']\n",
        "\n",
        "# 6. Train/test split (30%, stratified)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# 7. One-hot encode gender exactly as before\n",
        "X_train = pd.get_dummies(X_train, columns=['RIAGENDR'], drop_first=True)\n",
        "X_test  = pd.get_dummies(X_test,  columns=['RIAGENDR'], drop_first=True)\n",
        "\n",
        "# 8. Set up CV + grid search for RandomForest\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 300, 500],\n",
        "    'max_depth': [5, 10, 15, None],\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "grid_rf = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_grid,\n",
        "    scoring='roc_auc',\n",
        "    cv=cv,\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best CV AUC: {grid_rf.best_score_:.3f}\")\n",
        "print(f\"Best params: {grid_rf.best_params_}\")\n",
        "\n",
        "# 9. Evaluate on the test set\n",
        "best_rf = grid_rf.best_estimator_\n",
        "y_prob_rf = best_rf.predict_proba(X_test)[:,1]\n",
        "y_pred_rf = (y_prob_rf >= 0.5).astype(int)\n",
        "\n",
        "print(\"\\n--- Test set performance (threshold = 0.50) ---\")\n",
        "print(f\"ROC AUC: {roc_auc_score(y_test, y_prob_rf):.3f}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b15fbc14-4ddf-4e25-b384-186078436ec2",
      "metadata": {
        "id": "b15fbc14-4ddf-4e25-b384-186078436ec2"
      },
      "source": [
        "***1.4 Model Comparison: Logistic Regression vs. Random Forest***\n",
        "\n",
        "We trained two different classifiers to predict whether a participant is overweight/obese (BMI ≥ 25) using the same features, train/test split, and evaluation threshold (0.50). Here’s how they stack up:\n",
        "| Metric                  | Logistic Regression | Random Forest |\n",
        "| ----------------------- | ------------------- | ------------- |\n",
        "| **Cross-Val AUC**       | 0.972               | 0.969         |\n",
        "| **Test-Set AUC**        | 0.973               | 0.972         |\n",
        "| **Accuracy**            | 0.91                | 0.92          |\n",
        "| **Precision (Class 1)** | 0.97                | 0.94          |\n",
        "| **Recall (Class 1)**    | 0.90                | 0.95          |\n",
        "| **F1-Score (Class 1)**  | 0.93                | 0.94          |\n",
        "\n",
        "- Discrimination (AUC): Both models have very high AUCs (> 0.97), which shows that they are highly good at classifying participants according to risk. The difference between 0.973 and 0.972 is insignificant, yet logistic regression wins out by a small margin.\n",
        "- Overall Accuracy: Overall accuracy is slightly higher for Random Forest (92% vs. 91%), but both are good given class balance.\n",
        "- Class-Specific Performance:\n",
        "   - Precision (avoiding false positives): With a higher logistic regression coefficient (0.97 vs. 0.94), its \"overweight/obese\" predictions are more frequently accurate.\n",
        "   - Recall (capturing true positives): Because random forest performs better (0.95 vs. 0.90), it misses fewer real cases of overweight or obesity.\n",
        "   - This trade-off is reflected in the extremely similar F1-scores (harmonic mean) (0.93 vs. 0.94).\n",
        "\n",
        "***Which to Choose?***\n",
        "- The greater precision of logistic regression might be better if reducing false alarms—that is, just identifying people who are most likely overweight or obese—is ones top concern.\n",
        "- The higher recall of random forest is useful if catching as many true cases as possible is required, even if it means a few more false positives.\n",
        "- The simpler logistic regression may be adequate for most applications due to the near-tie in AUC and overall performance; however, the random forest is a good substitute if one expects complicated non-linear interactions or wants the little increase in recall."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1458a7d-8476-4582-ac10-f5b3b4e00249",
      "metadata": {
        "id": "a1458a7d-8476-4582-ac10-f5b3b4e00249"
      },
      "source": [
        "***1.5 Ethical Considerations and Data Privacy Issues***\n",
        "\n",
        "***1. Privacy and Re-identification Risk***\n",
        "- Concern: Particularly in a small sample, re-identification can be made possible even with pseudonymized participant IDs when paired with comprehensive health and dietary indicators (age, BMI, waist/hip measurements, nutrient intakes).\n",
        "- Mitigation: In public outputs, avoid sharing unique combinations of features, use broader categories (e.g., age bands instead of specific ages), and mask extreme values with modest random noise.\n",
        "\n",
        "***2. Data Security***\n",
        "- Concern: Sensitive health information may be exposed by unauthorized access or scraping of interactive dashboards and the underlying CSV files.\n",
        "- Mitigation: Implement stringent access controls, host visualizations behind authenticated portals, encrypt data in transit and at rest (HTTPS, encrypted storage), and regularly audit all servers and data handling programs for security flaws.\n",
        "\n",
        "***3. Stigmatization and Bias***\n",
        "- Concern: People might be shamed and subjected to harmful stereotypes when they are labeled as \"obese\" or \"high risk.\" Results may be overgeneralized by readers due to small, non-representative samples.\n",
        "- Mitigation: Employ neutral, clinical terminology (e.g. “BMI ≥30” rather than “obese”), clearly state sample size limitations, and use color palettes and legends that avoid alarmist connotations.\n",
        "\n",
        "***4. Informed Consent and Scope of Use***\n",
        "- Concern: It's possible that participants didn't expect their de-identified data to be integrated across several domains or feed into interactive dashboards that are accessible to the public.\n",
        "- Mitigation: Future research should make sure that participants receive private previews of how their data will appear, offer opt-out alternatives for specific analyses, and contain explicit consent language outlining possible data visualization and aggregation.\n",
        "\n",
        "***5. Interpretation and Causal Overreach***\n",
        "- Concern: Correlations shown (e.g. high sugar intake alongside high BMI) may be misconstrued as causal, and small sample size can produce spurious associations.\n",
        "- Mitigation: Display sample sizes and confidence intervals when appropriate, prominently state that \"correlation does not imply causation,\" and clearly state that the analysis is exploratory for each visualization.\n",
        "\n",
        "***6. Algorithmic and Metric Bias***\n",
        "- Concern: Standard BMI, WHR, and nutritional reference standards might not take age, sex, or ethnic variations into consideration, which could lead to some people being incorrectly classified.\n",
        "- Mitigation: When possible, include alternative or age-adjusted metrics, acknowledge the demographic specificity of cut-offs in documentation, and consult subject-matter experts to validate any threshold values that are employed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aaf4205-34ec-486d-9309-d30f69599f9f",
      "metadata": {
        "id": "6aaf4205-34ec-486d-9309-d30f69599f9f"
      },
      "source": [
        "***1.6 Conclusion***\n",
        "\n",
        "Our research clearly demonstrated higher cardiometabolic risk across the board, utilizing a comprehensive, integrated NHANES dataset that incorporated anthropometric, biochemical, nutritional, and behavioral measurements. Interactive scatterplots and stacked-bar charts showed widespread patterns of central adiposity (high WHR), overweight and obesity, and dietary imbalances, including too much sodium and added sugars and not enough fiber. These results were made tangible at the individual level by the participant dashboard, which made it possible to quickly identify outliers for focused intervention.\n",
        "\n",
        "Based on these descriptive findings, we created and refined two prediction models to differentiate between those who are normal weight and those who are overweight or obese: logistic regression and a random forest classifier. On the held-out test set, both methods demonstrated high discrimination (ROC AUC = 0.97) and comparable accuracy (~ 0.91–0.92), indicating that the risk signal is robustly captured by essential parameters (age, gender, waist and hip measures, cholesterol, and specific food intakes). Although both models performed fairly well, the random forest model marginally beat logistic regression in recall for the overweight/obese class, suggesting its benefit in capturing nonlinear relationships.\n",
        "\n",
        "Predictive modeling and visualizations work together to highlight the necessity of individualized preventative strategies: interactive dashboards inform lifestyle advice, while data-driven risk scores can identify high-risk individuals. Our insights and predictive capacity will be further refined in the future by increasing the sample size, adding longitudinal follow-up, and integrating more detailed dietary and genetic data—always supported by strict consent, privacy protections, and open governance."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}